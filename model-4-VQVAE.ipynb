{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe82a508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchview import draw_graph\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional  as Fn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from io import BytesIO\n",
    "from IPython.display import Image as IPyImage, display\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"VQVAE-Transformer\",  \n",
    "    name=\"experiment-1\",    \n",
    "    id=\"fe9htihr\",  # Same ID as before\n",
    "    resume=\"allow\"\n",
    "    config={                       \n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 16,\n",
    "    }\n",
    ")\n",
    "\n",
    "# wandb.init(\n",
    "#     project=\"experiment-1\",\n",
    "#     id=\"VQVAE-Transformer\",  # Same ID as before\n",
    "#     resume=\"allow\"  # or \"must\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b504dba",
   "metadata": {},
   "source": [
    "Implementation\n",
    "https://www.youtube.com/watch?v=1mi2MSvigcc&t=18s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be15cab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Title: model Pages: 1 -->\n",
       "<svg width=\"142pt\" height=\"580pt\"\n",
       " viewBox=\"0.00 0.00 141.50 580.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 576)\">\n",
       "<title>model</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-576 137.5,-576 137.5,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"113.5,-572 20,-572 20,-539.5 113.5,-539.5 113.5,-572\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"20,-539.5 20,-572 81,-572 81,-539.5 20,-539.5\"/>\n",
       "<text text-anchor=\"start\" x=\"25\" y=\"-557.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"34.38\" y=\"-546.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"81,-539.5 81,-572 113.5,-572 113.5,-539.5 81,-539.5\"/>\n",
       "<text text-anchor=\"start\" x=\"86\" y=\"-551.88\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1)</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"127.12,-503.5 6.38,-503.5 6.38,-461 127.12,-461 127.12,-503.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6.38,-461 6.38,-503.5 48.62,-503.5 48.62,-461 6.38,-461\"/>\n",
       "<text text-anchor=\"start\" x=\"14.38\" y=\"-484\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"11.38\" y=\"-472.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-482.25 48.62,-503.5 91.62,-503.5 91.62,-482.25 48.62,-482.25\"/>\n",
       "<text text-anchor=\"start\" x=\"58.12\" y=\"-489\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-482.25 91.62,-503.5 127.12,-503.5 127.12,-482.25 91.62,-482.25\"/>\n",
       "<text text-anchor=\"start\" x=\"96.62\" y=\"-489\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-461 48.62,-482.25 91.62,-482.25 91.62,-461 48.62,-461\"/>\n",
       "<text text-anchor=\"start\" x=\"53.62\" y=\"-467.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-461 91.62,-482.25 127.12,-482.25 127.12,-461 91.62,-461\"/>\n",
       "<text text-anchor=\"start\" x=\"96.62\" y=\"-467.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.75,-539.59C66.75,-532.32 66.75,-523.32 66.75,-514.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.25,-514.79 66.75,-504.79 63.25,-514.79 70.25,-514.79\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"127.12,-425 6.38,-425 6.38,-382.5 127.12,-382.5 127.12,-425\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6.38,-382.5 6.38,-425 48.62,-425 48.62,-382.5 6.38,-382.5\"/>\n",
       "<text text-anchor=\"start\" x=\"19.62\" y=\"-405.5\" font-family=\"Linux libertine\" font-size=\"10.00\">sub</text>\n",
       "<text text-anchor=\"start\" x=\"11.38\" y=\"-394.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-403.75 48.62,-425 91.62,-425 91.62,-403.75 48.62,-403.75\"/>\n",
       "<text text-anchor=\"start\" x=\"58.12\" y=\"-410.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-403.75 91.62,-425 127.12,-425 127.12,-403.75 91.62,-403.75\"/>\n",
       "<text text-anchor=\"start\" x=\"96.62\" y=\"-410.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-382.5 48.62,-403.75 91.62,-403.75 91.62,-382.5 48.62,-382.5\"/>\n",
       "<text text-anchor=\"start\" x=\"53.62\" y=\"-389.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-382.5 91.62,-403.75 127.12,-403.75 127.12,-382.5 91.62,-382.5\"/>\n",
       "<text text-anchor=\"start\" x=\"96.62\" y=\"-389.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.75,-461.15C66.75,-453.57 66.75,-444.75 66.75,-436.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.25,-436.49 66.75,-426.49 63.25,-436.49 70.25,-436.49\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"127.12,-346.5 6.38,-346.5 6.38,-304 127.12,-304 127.12,-346.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6.38,-304 6.38,-346.5 48.62,-346.5 48.62,-304 6.38,-304\"/>\n",
       "<text text-anchor=\"start\" x=\"18.5\" y=\"-327\" font-family=\"Linux libertine\" font-size=\"10.00\">pow</text>\n",
       "<text text-anchor=\"start\" x=\"11.38\" y=\"-315.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-325.25 48.62,-346.5 91.62,-346.5 91.62,-325.25 48.62,-325.25\"/>\n",
       "<text text-anchor=\"start\" x=\"58.12\" y=\"-332\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-325.25 91.62,-346.5 127.12,-346.5 127.12,-325.25 91.62,-325.25\"/>\n",
       "<text text-anchor=\"start\" x=\"96.62\" y=\"-332\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-304 48.62,-325.25 91.62,-325.25 91.62,-304 48.62,-304\"/>\n",
       "<text text-anchor=\"start\" x=\"53.62\" y=\"-310.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-304 91.62,-325.25 127.12,-325.25 127.12,-304 91.62,-304\"/>\n",
       "<text text-anchor=\"start\" x=\"96.62\" y=\"-310.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.75,-382.65C66.75,-375.07 66.75,-366.25 66.75,-357.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.25,-357.99 66.75,-347.99 63.25,-357.99 70.25,-357.99\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"127.12,-268 6.38,-268 6.38,-225.5 127.12,-225.5 127.12,-268\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6.38,-225.5 6.38,-268 48.62,-268 48.62,-225.5 6.38,-225.5\"/>\n",
       "<text text-anchor=\"start\" x=\"12.88\" y=\"-248.5\" font-family=\"Linux libertine\" font-size=\"10.00\">argmin</text>\n",
       "<text text-anchor=\"start\" x=\"11.38\" y=\"-237.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-246.75 48.62,-268 91.62,-268 91.62,-246.75 48.62,-246.75\"/>\n",
       "<text text-anchor=\"start\" x=\"58.12\" y=\"-253.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-246.75 91.62,-268 127.12,-268 127.12,-246.75 91.62,-246.75\"/>\n",
       "<text text-anchor=\"start\" x=\"96.62\" y=\"-253.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-225.5 48.62,-246.75 91.62,-246.75 91.62,-225.5 48.62,-225.5\"/>\n",
       "<text text-anchor=\"start\" x=\"53.62\" y=\"-232.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-225.5 91.62,-246.75 127.12,-246.75 127.12,-225.5 91.62,-225.5\"/>\n",
       "<text text-anchor=\"start\" x=\"100.75\" y=\"-232.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.75,-304.15C66.75,-296.57 66.75,-287.75 66.75,-279.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.25,-279.49 66.75,-269.49 63.25,-279.49 70.25,-279.49\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"133.5,-189.5 0,-189.5 0,-147 133.5,-147 133.5,-189.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-147 0,-189.5 63.25,-189.5 63.25,-147 0,-147\"/>\n",
       "<text text-anchor=\"start\" x=\"5\" y=\"-170\" font-family=\"Linux libertine\" font-size=\"10.00\">__getitem__</text>\n",
       "<text text-anchor=\"start\" x=\"15.5\" y=\"-158.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"63.25,-168.25 63.25,-189.5 106.25,-189.5 106.25,-168.25 63.25,-168.25\"/>\n",
       "<text text-anchor=\"start\" x=\"72.75\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"106.25,-168.25 106.25,-189.5 133.5,-189.5 133.5,-168.25 106.25,-168.25\"/>\n",
       "<text text-anchor=\"start\" x=\"111.25\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"63.25,-147 63.25,-168.25 106.25,-168.25 106.25,-147 63.25,-147\"/>\n",
       "<text text-anchor=\"start\" x=\"68.25\" y=\"-153.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"106.25,-147 106.25,-168.25 133.5,-168.25 133.5,-147 106.25,-147\"/>\n",
       "<text text-anchor=\"start\" x=\"111.25\" y=\"-153.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.75,-225.65C66.75,-218.07 66.75,-209.25 66.75,-200.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.25,-200.99 66.75,-190.99 63.25,-200.99 70.25,-200.99\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"123,-111 10.5,-111 10.5,-68.5 123,-68.5 123,-111\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"10.5,-68.5 10.5,-111 52.75,-111 52.75,-68.5 10.5,-68.5\"/>\n",
       "<text text-anchor=\"start\" x=\"18.5\" y=\"-91.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"15.5\" y=\"-80.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"52.75,-89.75 52.75,-111 95.75,-111 95.75,-89.75 52.75,-89.75\"/>\n",
       "<text text-anchor=\"start\" x=\"62.25\" y=\"-96.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"95.75,-89.75 95.75,-111 123,-111 123,-89.75 95.75,-89.75\"/>\n",
       "<text text-anchor=\"start\" x=\"100.75\" y=\"-96.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"52.75,-68.5 52.75,-89.75 95.75,-89.75 95.75,-68.5 52.75,-68.5\"/>\n",
       "<text text-anchor=\"start\" x=\"57.75\" y=\"-75.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"95.75,-68.5 95.75,-89.75 123,-89.75 123,-68.5 95.75,-68.5\"/>\n",
       "<text text-anchor=\"start\" x=\"100.75\" y=\"-75.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.75,-147.15C66.75,-139.57 66.75,-130.75 66.75,-122.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.25,-122.49 66.75,-112.49 63.25,-122.49 70.25,-122.49\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"112.38,-32.5 21.12,-32.5 21.12,0 112.38,0 112.38,-32.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"21.12,0 21.12,-32.5 88.12,-32.5 88.12,0 21.12,0\"/>\n",
       "<text text-anchor=\"start\" x=\"26.12\" y=\"-18\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"38.5\" y=\"-6.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"88.12,0 88.12,-32.5 112.38,-32.5 112.38,0 88.12,0\"/>\n",
       "<text text-anchor=\"start\" x=\"93.12\" y=\"-12.38\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.75,-68.83C66.75,-61.06 66.75,-52.03 66.75,-43.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.25,-43.81 66.75,-33.81 63.25,-43.81 70.25,-43.81\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1288ba510>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VQVAEQuantizeWithoutDerivative(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(1, 1)\n",
    "        self.codebook = nn.Parameter(torch.tensor([-5., -9., 0., 6., 9.]))\n",
    "        self.decoder = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_out = self.encoder(x)\n",
    "        l2_difference = (encoder_out - self.codebook) ** 2\n",
    "        nearest_index = torch.argmin(l2_difference, dim = -1)\n",
    "        # print(nearest_index)\n",
    "        decoder_input = self.codebook[nearest_index]\n",
    "        # print(decoder_input)\n",
    "        decoder_out = self.decoder(decoder_input)\n",
    "        return decoder_out\n",
    "\n",
    "q = VQVAEQuantizeWithoutDerivative()\n",
    "test = torch.ones(1).unsqueeze(0)\n",
    "out = q(test)\n",
    "# print(out)\n",
    "out.backward()\n",
    "model_graph = draw_graph(q, input_size = (1, 1))\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ccee7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Title: model Pages: 1 -->\n",
       "<svg width=\"232pt\" height=\"816pt\"\n",
       " viewBox=\"0.00 0.00 232.38 815.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 811.5)\">\n",
       "<title>model</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-811.5 228.38,-811.5 228.38,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"109.38,-807.5 15.88,-807.5 15.88,-775 109.38,-775 109.38,-807.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"15.88,-775 15.88,-807.5 76.88,-807.5 76.88,-775 15.88,-775\"/>\n",
       "<text text-anchor=\"start\" x=\"20.88\" y=\"-793\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"30.25\" y=\"-781.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"76.88,-775 76.88,-807.5 109.38,-807.5 109.38,-775 76.88,-775\"/>\n",
       "<text text-anchor=\"start\" x=\"81.88\" y=\"-787.38\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1)</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"123,-739 2.25,-739 2.25,-696.5 123,-696.5 123,-739\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2.25,-696.5 2.25,-739 44.5,-739 44.5,-696.5 2.25,-696.5\"/>\n",
       "<text text-anchor=\"start\" x=\"10.25\" y=\"-719.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"7.25\" y=\"-708.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"44.5,-717.75 44.5,-739 87.5,-739 87.5,-717.75 44.5,-717.75\"/>\n",
       "<text text-anchor=\"start\" x=\"54\" y=\"-724.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"87.5,-717.75 87.5,-739 123,-739 123,-717.75 87.5,-717.75\"/>\n",
       "<text text-anchor=\"start\" x=\"92.5\" y=\"-724.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"44.5,-696.5 44.5,-717.75 87.5,-717.75 87.5,-696.5 44.5,-696.5\"/>\n",
       "<text text-anchor=\"start\" x=\"49.5\" y=\"-703.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"87.5,-696.5 87.5,-717.75 123,-717.75 123,-696.5 87.5,-696.5\"/>\n",
       "<text text-anchor=\"start\" x=\"92.5\" y=\"-703.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.62,-775.09C62.62,-767.82 62.62,-758.82 62.62,-750.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.13,-750.29 62.63,-740.29 59.13,-750.29 66.13,-750.29\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"211,-660.5 90.25,-660.5 90.25,-618 211,-618 211,-660.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"90.25,-618 90.25,-660.5 132.5,-660.5 132.5,-618 90.25,-618\"/>\n",
       "<text text-anchor=\"start\" x=\"103.5\" y=\"-641\" font-family=\"Linux libertine\" font-size=\"10.00\">sub</text>\n",
       "<text text-anchor=\"start\" x=\"95.25\" y=\"-629.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"132.5,-639.25 132.5,-660.5 175.5,-660.5 175.5,-639.25 132.5,-639.25\"/>\n",
       "<text text-anchor=\"start\" x=\"142\" y=\"-646\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"175.5,-639.25 175.5,-660.5 211,-660.5 211,-639.25 175.5,-639.25\"/>\n",
       "<text text-anchor=\"start\" x=\"180.5\" y=\"-646\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"132.5,-618 132.5,-639.25 175.5,-639.25 175.5,-618 132.5,-618\"/>\n",
       "<text text-anchor=\"start\" x=\"137.5\" y=\"-624.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"175.5,-618 175.5,-639.25 211,-639.25 211,-618 175.5,-618\"/>\n",
       "<text text-anchor=\"start\" x=\"180.5\" y=\"-624.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M85.75,-696.65C95.87,-687.85 107.92,-677.38 118.87,-667.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"120.96,-670.68 126.21,-661.47 116.37,-665.39 120.96,-670.68\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"194.12,-346.5 53.12,-346.5 53.12,-304 194.12,-304 194.12,-346.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"53.12,-304 53.12,-346.5 95.38,-346.5 95.38,-304 53.12,-304\"/>\n",
       "<text text-anchor=\"start\" x=\"66.38\" y=\"-327\" font-family=\"Linux libertine\" font-size=\"10.00\">sub</text>\n",
       "<text text-anchor=\"start\" x=\"58.12\" y=\"-315.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"95.38,-325.25 95.38,-346.5 138.38,-346.5 138.38,-325.25 95.38,-325.25\"/>\n",
       "<text text-anchor=\"start\" x=\"104.88\" y=\"-332\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"138.38,-325.25 138.38,-346.5 194.12,-346.5 194.12,-325.25 138.38,-325.25\"/>\n",
       "<text text-anchor=\"start\" x=\"143.38\" y=\"-332\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,), (1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"95.38,-304 95.38,-325.25 138.38,-325.25 138.38,-304 95.38,-304\"/>\n",
       "<text text-anchor=\"start\" x=\"100.38\" y=\"-310.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"138.38,-304 138.38,-325.25 194.12,-325.25 194.12,-304 138.38,-304\"/>\n",
       "<text text-anchor=\"start\" x=\"153.5\" y=\"-310.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;6 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.62,-696.69C62.62,-667.14 62.63,-610.19 62.62,-561.75 62.62,-561.75 62.62,-561.75 62.62,-481.25 62.62,-436.56 63.58,-423.39 81.62,-382.5 85.81,-373.02 91.85,-363.64 98.04,-355.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.65,-357.67 104.08,-347.64 95.15,-353.34 100.65,-357.67\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"137.25,-189.5 0,-189.5 0,-147 137.25,-147 137.25,-189.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-147 0,-189.5 42.25,-189.5 42.25,-147 0,-147\"/>\n",
       "<text text-anchor=\"start\" x=\"13.25\" y=\"-170\" font-family=\"Linux libertine\" font-size=\"10.00\">add</text>\n",
       "<text text-anchor=\"start\" x=\"5\" y=\"-158.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"42.25,-168.25 42.25,-189.5 85.25,-189.5 85.25,-168.25 42.25,-168.25\"/>\n",
       "<text text-anchor=\"start\" x=\"51.75\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"85.25,-168.25 85.25,-189.5 137.25,-189.5 137.25,-168.25 85.25,-168.25\"/>\n",
       "<text text-anchor=\"start\" x=\"90.25\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">2 x (1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"42.25,-147 42.25,-168.25 85.25,-168.25 85.25,-147 42.25,-147\"/>\n",
       "<text text-anchor=\"start\" x=\"47.25\" y=\"-153.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"85.25,-147 85.25,-168.25 137.25,-168.25 137.25,-147 85.25,-147\"/>\n",
       "<text text-anchor=\"start\" x=\"98.5\" y=\"-153.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;8 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.38,-696.58C43.2,-667.36 24.63,-611.34 24.62,-561.75 24.62,-561.75 24.62,-561.75 24.62,-324.25 24.62,-279.66 41.69,-230.49 54.56,-199.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"57.73,-201.25 58.48,-190.68 51.3,-198.47 57.73,-201.25\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"212,-582 91.25,-582 91.25,-539.5 212,-539.5 212,-582\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.25,-539.5 91.25,-582 133.5,-582 133.5,-539.5 91.25,-539.5\"/>\n",
       "<text text-anchor=\"start\" x=\"103.38\" y=\"-562.5\" font-family=\"Linux libertine\" font-size=\"10.00\">pow</text>\n",
       "<text text-anchor=\"start\" x=\"96.25\" y=\"-551.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"133.5,-560.75 133.5,-582 176.5,-582 176.5,-560.75 133.5,-560.75\"/>\n",
       "<text text-anchor=\"start\" x=\"143\" y=\"-567.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"176.5,-560.75 176.5,-582 212,-582 212,-560.75 176.5,-560.75\"/>\n",
       "<text text-anchor=\"start\" x=\"181.5\" y=\"-567.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"133.5,-539.5 133.5,-560.75 176.5,-560.75 176.5,-539.5 133.5,-539.5\"/>\n",
       "<text text-anchor=\"start\" x=\"138.5\" y=\"-546.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"176.5,-539.5 176.5,-560.75 212,-560.75 212,-539.5 176.5,-539.5\"/>\n",
       "<text text-anchor=\"start\" x=\"181.5\" y=\"-546.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M150.89,-618.15C150.99,-610.57 151.1,-601.75 151.21,-593.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.71,-593.54 151.34,-583.49 147.71,-593.45 154.71,-593.54\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"214,-503.5 93.25,-503.5 93.25,-461 214,-461 214,-503.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"93.25,-461 93.25,-503.5 135.5,-503.5 135.5,-461 93.25,-461\"/>\n",
       "<text text-anchor=\"start\" x=\"99.75\" y=\"-484\" font-family=\"Linux libertine\" font-size=\"10.00\">argmin</text>\n",
       "<text text-anchor=\"start\" x=\"98.25\" y=\"-472.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"135.5,-482.25 135.5,-503.5 178.5,-503.5 178.5,-482.25 135.5,-482.25\"/>\n",
       "<text text-anchor=\"start\" x=\"145\" y=\"-489\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"178.5,-482.25 178.5,-503.5 214,-503.5 214,-482.25 178.5,-482.25\"/>\n",
       "<text text-anchor=\"start\" x=\"183.5\" y=\"-489\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"135.5,-461 135.5,-482.25 178.5,-482.25 178.5,-461 135.5,-461\"/>\n",
       "<text text-anchor=\"start\" x=\"140.5\" y=\"-467.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"178.5,-461 178.5,-482.25 214,-482.25 214,-461 178.5,-461\"/>\n",
       "<text text-anchor=\"start\" x=\"187.62\" y=\"-467.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M152.15,-539.65C152.35,-532.07 152.58,-523.25 152.8,-514.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.29,-515.08 153.06,-504.99 149.3,-514.9 156.29,-515.08\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"224.38,-425 90.88,-425 90.88,-382.5 224.38,-382.5 224.38,-425\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"90.88,-382.5 90.88,-425 154.12,-425 154.12,-382.5 90.88,-382.5\"/>\n",
       "<text text-anchor=\"start\" x=\"95.88\" y=\"-405.5\" font-family=\"Linux libertine\" font-size=\"10.00\">__getitem__</text>\n",
       "<text text-anchor=\"start\" x=\"106.38\" y=\"-394.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"154.12,-403.75 154.12,-425 197.12,-425 197.12,-403.75 154.12,-403.75\"/>\n",
       "<text text-anchor=\"start\" x=\"163.62\" y=\"-410.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"197.12,-403.75 197.12,-425 224.38,-425 224.38,-403.75 197.12,-403.75\"/>\n",
       "<text text-anchor=\"start\" x=\"202.12\" y=\"-410.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"154.12,-382.5 154.12,-403.75 197.12,-403.75 197.12,-382.5 154.12,-382.5\"/>\n",
       "<text text-anchor=\"start\" x=\"159.12\" y=\"-389.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"197.12,-382.5 197.12,-403.75 224.38,-403.75 224.38,-382.5 197.12,-382.5\"/>\n",
       "<text text-anchor=\"start\" x=\"202.12\" y=\"-389.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.68,-461.15C155.07,-453.57 155.53,-444.75 155.97,-436.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.46,-436.66 156.49,-426.49 152.47,-436.3 159.46,-436.66\"/>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.69,-382.65C145.21,-374.81 141.13,-365.64 137.29,-357\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"140.49,-355.58 133.23,-347.86 134.09,-358.42 140.49,-355.58\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"178,-268 57.25,-268 57.25,-225.5 178,-225.5 178,-268\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"57.25,-225.5 57.25,-268 99.5,-268 99.5,-225.5 57.25,-225.5\"/>\n",
       "<text text-anchor=\"start\" x=\"63.75\" y=\"-248.5\" font-family=\"Linux libertine\" font-size=\"10.00\">detach</text>\n",
       "<text text-anchor=\"start\" x=\"62.25\" y=\"-237.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"99.5,-246.75 99.5,-268 142.5,-268 142.5,-246.75 99.5,-246.75\"/>\n",
       "<text text-anchor=\"start\" x=\"109\" y=\"-253.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"142.5,-246.75 142.5,-268 178,-268 178,-246.75 142.5,-246.75\"/>\n",
       "<text text-anchor=\"start\" x=\"147.5\" y=\"-253.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"99.5,-225.5 99.5,-246.75 142.5,-246.75 142.5,-225.5 99.5,-225.5\"/>\n",
       "<text text-anchor=\"start\" x=\"104.5\" y=\"-232.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"142.5,-225.5 142.5,-246.75 178,-246.75 178,-225.5 142.5,-225.5\"/>\n",
       "<text text-anchor=\"start\" x=\"147.5\" y=\"-232.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122.05,-304.15C121.45,-296.57 120.76,-287.75 120.1,-279.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"123.6,-279.19 119.33,-269.49 116.62,-279.73 123.6,-279.19\"/>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M104.75,-225.65C99.56,-217.55 93.46,-208.02 87.77,-199.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.74,-197.29 82.4,-190.76 84.85,-201.06 90.74,-197.29\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"129,-111 8.25,-111 8.25,-68.5 129,-68.5 129,-111\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8.25,-68.5 8.25,-111 50.5,-111 50.5,-68.5 8.25,-68.5\"/>\n",
       "<text text-anchor=\"start\" x=\"16.25\" y=\"-91.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"13.25\" y=\"-80.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"50.5,-89.75 50.5,-111 93.5,-111 93.5,-89.75 50.5,-89.75\"/>\n",
       "<text text-anchor=\"start\" x=\"60\" y=\"-96.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"93.5,-89.75 93.5,-111 129,-111 129,-89.75 93.5,-89.75\"/>\n",
       "<text text-anchor=\"start\" x=\"98.5\" y=\"-96.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"50.5,-68.5 50.5,-89.75 93.5,-89.75 93.5,-68.5 50.5,-68.5\"/>\n",
       "<text text-anchor=\"start\" x=\"55.5\" y=\"-75.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"93.5,-68.5 93.5,-89.75 129,-89.75 129,-68.5 93.5,-68.5\"/>\n",
       "<text text-anchor=\"start\" x=\"98.5\" y=\"-75.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.62,-147.15C68.62,-139.57 68.62,-130.75 68.62,-122.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"72.13,-122.49 68.63,-112.49 65.13,-122.49 72.13,-122.49\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"118.38,-32.5 18.88,-32.5 18.88,0 118.38,0 118.38,-32.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"18.88,0 18.88,-32.5 85.88,-32.5 85.88,0 18.88,0\"/>\n",
       "<text text-anchor=\"start\" x=\"23.88\" y=\"-18\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"36.25\" y=\"-6.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"85.88,0 85.88,-32.5 118.38,-32.5 118.38,0 85.88,0\"/>\n",
       "<text text-anchor=\"start\" x=\"90.88\" y=\"-12.38\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.62,-68.83C68.62,-61.06 68.62,-52.03 68.62,-43.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"72.13,-43.81 68.63,-33.81 65.13,-43.81 72.13,-43.81\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1085a20d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VQVAEQuantizeWithDerivative(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(1, 1)\n",
    "        self.codebook = nn.Parameter(torch.tensor([-5., -9., 0., 6., 9.]))\n",
    "        self.decoder = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_out = self.encoder(x)\n",
    "        l2_difference = (encoder_out - self.codebook) ** 2\n",
    "        nearest_index = torch.argmin(l2_difference, dim = -1)\n",
    "        # print(nearest_index)\n",
    "        decoder_input = self.codebook[nearest_index]\n",
    "        # print(decoder_input)\n",
    "        decoder_input = encoder_out + (decoder_input - encoder_out).detach()\n",
    "        decoder_out = self.decoder(decoder_input)\n",
    "        return decoder_out\n",
    "\n",
    "q = VQVAEQuantizeWithDerivative()\n",
    "test = torch.ones(1).unsqueeze(0)\n",
    "out = q(test)\n",
    "# print(out)\n",
    "out.backward()\n",
    "model_graph = draw_graph(q, input_size = (1, 1))\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b1877a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4845, -0.4609,  1.1024,  ..., -0.0325,  0.2189, -1.2672],\n",
       "        [-0.6749,  0.4468, -0.3136,  ...,  0.1709, -0.0265, -1.3246],\n",
       "        [-0.5988,  0.2219,  0.1161,  ..., -0.1803,  0.4541,  0.1926],\n",
       "        ...,\n",
       "        [ 0.0512,  0.0261,  0.7224,  ..., -0.5471,  0.2744, -0.1748],\n",
       "        [-0.1059,  0.3429,  0.1086,  ..., -0.8707, -1.5602,  0.7121],\n",
       "        [ 0.6403, -1.5013, -0.3234,  ..., -0.6487,  0.2742, -0.2925]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorQuantize(nn.Module):\n",
    "    def __init__(self, codeBookDim = 256, embeddingDim = 128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.codeBookDim = codeBookDim\n",
    "        self.embeddingDim = embeddingDim\n",
    "        self.codeBook = nn.Parameter(torch.randn(codeBookDim, embeddingDim))\n",
    "        self.register_buffer(\"cluster_size\", torch.zeros(codeBookDim))\n",
    "        self.register_buffer(\"ema_w\", torch.randn(codeBookDim, embeddingDim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        reshaped_x = x.view(-1, self.embeddingDim)\n",
    "        \n",
    "        distance = (\n",
    "            torch.sum(reshaped_x**2, dim=1, keepdim=True)\n",
    "            - 2 * torch.matmul(reshaped_x, self.codeBook.t())\n",
    "            + torch.sum(self.codeBook**2, dim=1)\n",
    "        )\n",
    "        \n",
    "        logits = -distance\n",
    "        soft_one_hot = Fn.gumbel_softmax(logits, tau=1.0, hard=False)\n",
    "        quantized = torch.matmul(soft_one_hot, self.codeBook)\n",
    "        quantized = quantized.view_as(x)\n",
    "        quantized_latents = x + (quantized - x).detach()\n",
    "\n",
    "\n",
    "        return quantized_latents\n",
    "\n",
    "        \n",
    "vq = VectorQuantize(codeBookDim=512,embeddingDim=32)\n",
    "rand = torch.randn(1024,8)\n",
    "vq(rand)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "866b16b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 128, 32, 32]),\n",
       " torch.Size([32, 1, 64, 64]),\n",
       " tensor(0.9724, grad_fn=<MeanBackward0>),\n",
       " tensor(0.9724, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VecQVAE(nn.Module):\n",
    "    def __init__(self, inChannels = 1, hiddenDim = 32, codeBookdim = 128, embedDim = 128):\n",
    "        super().__init__()\n",
    "        self.inChannels = inChannels\n",
    "        self.hiddenDim = hiddenDim\n",
    "        self.codeBookdim = codeBookdim\n",
    "        self.embedDim = embedDim\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = inChannels, out_channels = hiddenDim, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(hiddenDim),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels = hiddenDim, out_channels = 2 * hiddenDim, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(2*hiddenDim),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(in_channels = 2 * hiddenDim, out_channels = embedDim, kernel_size = 3, stride = 2, padding = 1),\n",
    "            nn.BatchNorm2d(embedDim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.vector_quantize = VectorQuantize(codeBookDim=codeBookdim,embeddingDim=embedDim)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels = embedDim, out_channels = 2 * hiddenDim, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(2 * hiddenDim),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = 2 * hiddenDim, out_channels = hiddenDim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(hiddenDim),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels = hiddenDim, out_channels = inChannels, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, inChannels, height, width = x.shape\n",
    "        encodedOut = self.encoder(x)\n",
    "        batch_size, encoded_channel, encoded_height, encoded_width = encodedOut.shape\n",
    "        \n",
    "        # print(f\"Encoded Shape: {encodedOut.shape}\")\n",
    "\n",
    "        \n",
    "        vectorize_input = rearrange(encodedOut, 'b c h w -> (b h w) c')\n",
    "        quantized_vectors = self.vector_quantize(vectorize_input)\n",
    "        codebook_loss = torch.mean((quantized_vectors - vectorize_input.detach())**2)\n",
    "        commitment_loss = torch.mean((quantized_vectors.detach() - vectorize_input)**2)\n",
    "\n",
    "        quantized_vectors = vectorize_input + (quantized_vectors - vectorize_input).detach()\n",
    "        # print(f\"CodeBook Loss: {codebook_loss} , Commitment Loss: {commitment_loss}\")\n",
    "        # print(f\"Quantized SHape: {quantized_vectors.shape}\")\n",
    "\n",
    "        decoder_input = rearrange(quantized_vectors, '(b h w) d -> b d h w', d = encoded_channel, h = encoded_height, w = encoded_width)\n",
    "        # print(f\"Decoded Input SHape: {decoder_input.shape}\")\n",
    "        decodedOut = self.decoder(decoder_input)\n",
    "\n",
    "        # print(f\"Decoded SHape: {decodedOut.shape}\")\n",
    "        \n",
    "        return decoder_input, decodedOut, codebook_loss, commitment_loss\n",
    "\n",
    "VQ = VecQVAE(inChannels = 1, hiddenDim = 128, codeBookdim = 128, embedDim = 128)\n",
    "test = torch.randn(32, 1, 64, 64)\n",
    "quantized_latents, decoderOut, codebook_loss, commitment_loss = VQ(test)\n",
    "quantized_latents.shape, decoderOut.shape, codebook_loss, commitment_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be677e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 10000, 64, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 20, 1, 64, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"data/MovingMNIST/mnist_test_seq.npy\")\n",
    "print(data.shape)\n",
    "data = np.transpose(data, (1, 0, 2, 3))\n",
    "data = torch.from_numpy(data)\n",
    "data = data.unsqueeze(2)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe654757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64, 64]), torch.Size([1, 64, 64]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MakeFrameDataset(Dataset):\n",
    "    def __init__(self, video, input_length=10, output_length=10):\n",
    "        super().__init__()\n",
    "        num_videos, num_frames, C, H, W = video.shape\n",
    "        self.frames = video.reshape(-1, C, H, W)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.frames.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame = self.frames[idx]\n",
    "        return frame, frame\n",
    "    \n",
    "test = torch.randn(32, 20, 1, 64, 64)\n",
    "out = MakeFrameDataset(test)\n",
    "x, y = out.__getitem__(0)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a30c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torchDataset = MakeFrameDataset(data)\n",
    "dataloader = DataLoader(torchDataset, batch_size=64, shuffle = True)\n",
    "modelA = VecQVAE(inChannels = 1, hiddenDim = 128, codeBookdim = 128, embedDim = 128).to(device)\n",
    "lossFn = nn.MSELoss()\n",
    "optimizerA = optim.Adam(modelA.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "schedulerA = StepLR(optimizerA, step_size=50, gamma=0.8)\n",
    "\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e3d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelValA = torch.load(\"./model/VQVAE/vqvae.pt\", map_location=torch.device('cpu'))\n",
    "# modelA.load_state_dict(modelValA)\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "    modelA.train()\n",
    "    reconstruct_loss = 0.0\n",
    "    codeb_loss = 0.0\n",
    "    commit_loss = 0.0\n",
    "    \n",
    "    vqvaeloss = 0.0\n",
    "    loop = tqdm(dataloader, f\"{each_epoch}/{epochs}\")\n",
    "    for X, Y in loop:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        quantized_latents, decoderOut, codebook_loss, commitment_loss = modelA(X)\n",
    "        reconstruction_loss = torch.mean((Y - decoderOut)**2)\n",
    "        loss = reconstruction_loss + codebook_loss + 0.25 * commitment_loss\n",
    "        vqvaeloss += loss.item()\n",
    "\n",
    "        reconstruct_loss += reconstruction_loss.item()\n",
    "        codeb_loss += codebook_loss.item()\n",
    "        commit_loss += commitment_loss.item()\n",
    "        \n",
    "        optimizerA.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(modelA.parameters(), max_norm=1.0)\n",
    "        optimizerA.step()\n",
    "        loop.set_postfix({\"TotalL\": f\"{vqvaeloss}\", \"ReconsL\": f\"{reconstruct_loss}\", \"CodeL\":f\"{codeb_loss}\",\n",
    "                          \"CommitL\":f\"{commitment_loss}\"})\n",
    "    #     break\n",
    "    # break\n",
    "    \n",
    "    vqvaeloss /= len(dataloader)   \n",
    "    reconstruct_loss /= len(dataloader)   \n",
    "    codeb_loss /= len(dataloader)   \n",
    "    commit_loss /= len(dataloader)   \n",
    "    torch.save(modelA.state_dict(), \"./model/VQVAE/vqvae.pt\")\n",
    "    wandb.log({\n",
    "        \"Epoch\": each_epoch,\n",
    "        \"VQVAE LR\": optimizerA.param_groups[0]['lr'],\n",
    "        \"VQVAE Loss\": vqvaeloss,\n",
    "        \"Reconstruction Loss\": reconstruct_loss,\n",
    "        \"Codebook Loss\": codeb_loss,\n",
    "        \"Commitment Loss\": commit_loss,\n",
    "    })\n",
    "    schedulerA.step()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cd0d269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelValA = torch.load(\"./model/VQVAE/vqvae.pt\", map_location=torch.device('cpu'))\n",
    "modelA.load_state_dict(modelValA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b424cea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0, 0, ...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8a57839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_image = torch.randn(1, 1, 64, 64)\n",
    "temp_image = data[0, 10, ...].squeeze()\n",
    "image_np = temp_image.numpy().astype(np.uint8)\n",
    "image = Image.fromarray(image_np, mode='L') \n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"Image from Tensor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79dac303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 64])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data[0, 10, ...].unsqueeze(0)/255.0\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a12f2a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_image, _, _, _ = modelA(test_data)\n",
    "out_image = out_image.squeeze()\n",
    "image_np = (out_image * 255).clamp(0, 255).byte().cpu().numpy()\n",
    "\n",
    "\n",
    "# image_np = out_image.numpy().astype(np.uint8)\n",
    "image = Image.fromarray(image_np, mode='L') \n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"Image from Tensor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81659969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6043f395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429479c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026557f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d85b86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2560])\n"
     ]
    }
   ],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size=512, seq_length = 10, embed_dim=256, num_heads=4, feed_forward_dim=512):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, seq_length, embed_dim, embed_dim))\n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=feed_forward_dim,\n",
    "            dropout=0.1,\n",
    "            batch_first=True  # Use batch-first format\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=6)\n",
    "        \n",
    "        self.output_layer = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch, features = x.shape\n",
    "        x = rearrange(x, 'b (s e) -> b s e', e = self.embed_dim, s = self.seq_length)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x = x + self.positional_encoding\n",
    "        x = rearrange(x, 'b s e d -> b (s e) d', e = self.embed_dim, s = self.seq_length)\n",
    "        x = self.encoder(x)\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        x = rearrange(x, 'b s e -> b (s e)')\n",
    "        \n",
    "        return x\n",
    "\n",
    " \n",
    "tr = Transformer()\n",
    "test = torch.randint(0, 10, (2, 2560))\n",
    "\n",
    "out = tr(test)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad09de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/q2s37ndx6tg3lpzp3vp8xk_r0000gn/T/ipykernel_11585/2549432269.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(input_frames, dtype=torch.float32),\n",
      "/var/folders/y8/q2s37ndx6tg3lpzp3vp8xk_r0000gn/T/ipykernel_11585/2549432269.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(output_frames, dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 1, 4, 4]), torch.Size([10, 1, 4, 4]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MakeVideoDataset(Dataset):\n",
    "    def __init__(self, video, input_length=10, output_length=10):\n",
    "        super().__init__()\n",
    "        self.video = video\n",
    "        self.input_length = input_length\n",
    "        self.output_length = output_length\n",
    "        self.batch_size, self.seq_len, _, _, _ = video.shape\n",
    "\n",
    "        self.samples_per_video = self.seq_len - input_length - output_length + 1\n",
    "        self.total_samples = self.batch_size * self.samples_per_video\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_idx = idx // self.samples_per_video\n",
    "        time_idx = idx % self.samples_per_video\n",
    "\n",
    "        input_frames = self.video[batch_idx, time_idx:time_idx + self.input_length]\n",
    "        output_frames = self.video[batch_idx, time_idx + self.input_length:time_idx + self.input_length + self.output_length]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(input_frames, dtype=torch.float32),\n",
    "            torch.tensor(output_frames, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "    \n",
    "    \n",
    "test = torch.randn(32, 20, 1, 4, 4)\n",
    "out = MakeVideoDataset(test)\n",
    "x, y = out.__getitem__(0)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2faea622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 10000, 64, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 20, 1, 64, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"data/MovingMNIST/mnist_test_seq.npy\")\n",
    "print(data.shape)\n",
    "data = np.transpose(data, (1, 0, 2, 3))\n",
    "data = torch.from_numpy(data)\n",
    "data = data.unsqueeze(2)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2687cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.cuda.is_available() else 'cpu')\n",
    "torchDataset = MakeVideoDataset(data)\n",
    "dataloader = DataLoader(torchDataset, batch_size=8, shuffle = True)\n",
    "\n",
    "transformer_celoss =nn.CrossEntropyLoss()\n",
    "modelA = Transformer().to(device)\n",
    "modelB = VecQVAE().to(device)\n",
    "\n",
    "optimizerA = optim.AdamW(modelA.parameters(), lr=5e-5)\n",
    "optimizerB = optim.Adam(modelB.parameters(), lr=2e-4)\n",
    "schedulerA = StepLR(optimizerA, step_size=10, gamma=0.5)  \n",
    "schedulerB = StepLR(optimizerB, step_size=20, gamma=0.7)  \n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7972105a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0/50:   0%|          | 0/1250 [00:00<?, ?it/s]/var/folders/y8/q2s37ndx6tg3lpzp3vp8xk_r0000gn/T/ipykernel_11585/2549432269.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(input_frames, dtype=torch.float32),\n",
      "/var/folders/y8/q2s37ndx6tg3lpzp3vp8xk_r0000gn/T/ipykernel_11585/2549432269.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(output_frames, dtype=torch.float32)\n",
      "0/50:   0%|          | 0/1250 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m outputCodeboobIndices = torch.cat(output_indices, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# print(inputCodeboobIndices.shape)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m predX = \u001b[43mmodelA\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputCodeboobIndices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# y = modelA(outputCodeboobIndices)\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# print(predX.shape, inputCodeboobIndices.shape, outputCodeboobIndices.shape)\u001b[39;00m\n\u001b[32m     36\u001b[39m predX = rearrange(predX, \u001b[33m'\u001b[39m\u001b[33mb (d l) -> b d l\u001b[39m\u001b[33m'\u001b[39m, l = \u001b[32m10\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     28\u001b[39m x = x + \u001b[38;5;28mself\u001b[39m.positional_encoding\n\u001b[32m     29\u001b[39m x = rearrange(x, \u001b[33m'\u001b[39m\u001b[33mb s e d -> b (s e) d\u001b[39m\u001b[33m'\u001b[39m, e = \u001b[38;5;28mself\u001b[39m.embed_dim, s = \u001b[38;5;28mself\u001b[39m.seq_length)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m x = \u001b[38;5;28mself\u001b[39m.output_layer(x)\n\u001b[32m     33\u001b[39m x = rearrange(x, \u001b[33m'\u001b[39m\u001b[33mb s e -> b (s e)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/transformer.py:517\u001b[39m, in \u001b[36mTransformerEncoder.forward\u001b[39m\u001b[34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    514\u001b[39m is_causal = _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     output = \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[32m    525\u001b[39m     output = output.to_padded_tensor(\u001b[32m0.0\u001b[39m, src.size())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/transformer.py:920\u001b[39m, in \u001b[36mTransformerEncoderLayer.forward\u001b[39m\u001b[34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    916\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m._ff_block(\u001b[38;5;28mself\u001b[39m.norm2(x))\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    918\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm1(\n\u001b[32m    919\u001b[39m         x\n\u001b[32m--> \u001b[39m\u001b[32m920\u001b[39m         + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    921\u001b[39m     )\n\u001b[32m    922\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm2(x + \u001b[38;5;28mself\u001b[39m._ff_block(x))\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/transformer.py:934\u001b[39m, in \u001b[36mTransformerEncoderLayer._sa_block\u001b[39m\u001b[34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sa_block\u001b[39m(\n\u001b[32m    928\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    929\u001b[39m     x: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    932\u001b[39m     is_causal: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    933\u001b[39m ) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m934\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    943\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout1(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/activation.py:1373\u001b[39m, in \u001b[36mMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   1347\u001b[39m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[32m   1348\u001b[39m         query,\n\u001b[32m   1349\u001b[39m         key,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1370\u001b[39m         is_causal=is_causal,\n\u001b[32m   1371\u001b[39m     )\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m     attn_output, attn_output_weights = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m), attn_output_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/functional.py:6410\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   6407\u001b[39m k = k.view(bsz, num_heads, src_len, head_dim)\n\u001b[32m   6408\u001b[39m v = v.view(bsz, num_heads, src_len, head_dim)\n\u001b[32m-> \u001b[39m\u001b[32m6410\u001b[39m attn_output = \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   6411\u001b[39m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\n\u001b[32m   6412\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6413\u001b[39m attn_output = (\n\u001b[32m   6414\u001b[39m     attn_output.permute(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m).contiguous().view(bsz * tgt_len, embed_dim)\n\u001b[32m   6415\u001b[39m )\n\u001b[32m   6417\u001b[39m attn_output = linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for each_epoch in range(epochs):\n",
    "\n",
    "    loop = tqdm(dataloader, f\"{each_epoch}/{epochs}\")\n",
    "    for datapoint in loop:\n",
    "        # print(datapoint[0].shape, datapoint[1].shape)\n",
    "        datapoint[0] = datapoint[0]/255.0\n",
    "        datapoint[1] = datapoint[1]/255.0\n",
    "\n",
    "        input_indices = []\n",
    "        output_indices = []\n",
    "        vqvaeloss = 0.0\n",
    "        transformer_loss = 0.0\n",
    "        totalLoss = 0.0\n",
    "\n",
    "        for each_frame_index in range(datapoint[0].shape[1]):\n",
    "            each_input_frame = datapoint[0][:, each_frame_index, ...]\n",
    "            each_input_frame = each_input_frame.to(device)\n",
    "            out, ez, qz, inputindex = modelB(each_input_frame)\n",
    "            vqvaeloss += VecQVAELoss(each_input_frame, out, ez, qz)\n",
    "\n",
    "            each_output_frame = datapoint[1][:, each_frame_index, ...]\n",
    "            each_output_frame = each_output_frame.to(device)\n",
    "            out, ez, qz, outputindex = modelB(each_output_frame)\n",
    "            vqvaeloss += VecQVAELoss(each_output_frame, out, ez, qz)\n",
    "\n",
    "            input_indices.append(inputindex)\n",
    "            output_indices.append(outputindex)\n",
    "\n",
    "        # print(vqvaeloss)\n",
    "        inputCodeboobIndices = torch.cat(input_indices, dim=-1)\n",
    "        outputCodeboobIndices = torch.cat(output_indices, dim=-1)\n",
    "        inputCodeboobIndices = inputCodeboobIndices.to(device)\n",
    "        outputCodeboobIndices = outputCodeboobIndices.to(device)\n",
    "\n",
    "        # print(inputCodeboobIndices.shape)\n",
    "        predX = modelA(inputCodeboobIndices)\n",
    "        # y = modelA(outputCodeboobIndices)\n",
    "        # print(predX.shape, inputCodeboobIndices.shape, outputCodeboobIndices.shape)\n",
    "        \n",
    "        predX = rearrange(predX, 'b (d l) -> b d l', l = 10)\n",
    "        outputCodeboobIndices = rearrange(outputCodeboobIndices, 'b (d l) -> b d l', l = 10)\n",
    "\n",
    "        loss = transformer_celoss(predX, outputCodeboobIndices.float())\n",
    "        # # transformer_loss += loss.item()\n",
    "\n",
    "        combined_loss = loss + vqvaeloss\n",
    "        \n",
    "\n",
    "        optimizerA.zero_grad()\n",
    "        optimizerB.zero_grad()\n",
    "\n",
    "        combined_loss.backward()\n",
    "\n",
    "        optimizerA.step()\n",
    "        optimizerB.step()\n",
    "        loop.set_postfix({\"VQVAE Loss\": f\"{vqvaeloss.item()}\", \" Transformer Loss\": f\"{loss.item()}\", \" Total Loss\": f\"{combined_loss.item()}\"})\n",
    "        \n",
    "    # if each_epoch % 5 == 0:\n",
    "    torch.save(modelA.state_dict(), \"./model/VQVAE/transformer.pt\")\n",
    "    torch.save(modelB.state_dict(), \"./model/VQVAE/vqvae.pt\")\n",
    "    wandb.log({\n",
    "        \"Epoch\": each_epoch,\n",
    "        \"VQVAE Loss\": vqvaeloss.item(),\n",
    "        \"Transformer Loss\": loss.item(),\n",
    "        \"Total Loss\": combined_loss.item(),\n",
    "        \"Transformer LR\" : optimizerA.param_groups[0]['lr'],\n",
    "        \"VQVAE LR\": optimizerB.param_groups[0]['lr']\n",
    "    })\n",
    "\n",
    "    schedulerA.step()\n",
    "    schedulerB.step()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbd09236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 20, 64, 64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"data/MovingMNIST/mnist_test_seq.npy\")\n",
    "data = np.transpose(data, (1, 0, 2, 3))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac07a0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/gif": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualizeData(sequence):\n",
    "\n",
    "    frames = [Image.fromarray((frame * 255).astype(np.uint8), mode='L') for frame in sequence]\n",
    "\n",
    "    buffer = BytesIO()\n",
    "    frames[0].save(\n",
    "        buffer,\n",
    "        format='GIF',\n",
    "        save_all=True,\n",
    "        append_images=frames[1:],\n",
    "        duration=100,\n",
    "        loop=0\n",
    "    )\n",
    "\n",
    "    buffer.seek(0)\n",
    "    display(IPyImage(data=buffer.getvalue()))\n",
    "\n",
    "visualizeData(data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e03ed97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelValA = torch.load(\"model/VQVAE/transformer.pt\", map_location=torch.device('mps'))\n",
    "modelA.load_state_dict(modelValA)\n",
    "\n",
    "modelValB = torch.load(\"model/VQVAE/vqvae.pt\", map_location=torch.device('mps'))\n",
    "modelB.load_state_dict(modelValB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e0c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_frame = torch.from_numpy(data[0, 10]/255.0)\n",
    "\n",
    "initial_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38bcd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
