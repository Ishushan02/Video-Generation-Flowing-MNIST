{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe82a508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchview import draw_graph\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional  as Fn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from io import BytesIO\n",
    "from IPython.display import Image as IPyImage, display\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"VQVAE-Transformer\",  \n",
    "    name=\"experiment-1\",    \n",
    "    id=\"fe9htihr\",  # Same ID as before\n",
    "    resume=\"allow\"\n",
    "    config={                       \n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 16,\n",
    "    }\n",
    ")\n",
    "\n",
    "# wandb.init(\n",
    "#     project=\"experiment-1\",\n",
    "#     id=\"VQVAE-Transformer\",  # Same ID as before\n",
    "#     resume=\"allow\"  # or \"must\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b504dba",
   "metadata": {},
   "source": [
    "Implementation\n",
    "https://www.youtube.com/watch?v=1mi2MSvigcc&t=18s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be15cab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Title: model Pages: 1 -->\n",
       "<svg width=\"142pt\" height=\"580pt\"\n",
       " viewBox=\"0.00 0.00 141.50 580.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 576)\">\n",
       "<title>model</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-576 137.5,-576 137.5,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"113.5,-572 20,-572 20,-539.5 113.5,-539.5 113.5,-572\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"20,-539.5 20,-572 81,-572 81,-539.5 20,-539.5\"/>\n",
       "<text text-anchor=\"start\" x=\"25\" y=\"-557.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"34.38\" y=\"-546.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"81,-539.5 81,-572 113.5,-572 113.5,-539.5 81,-539.5\"/>\n",
       "<text text-anchor=\"start\" x=\"86\" y=\"-551.88\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1)</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"127.12,-503.5 6.38,-503.5 6.38,-461 127.12,-461 127.12,-503.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6.38,-461 6.38,-503.5 48.62,-503.5 48.62,-461 6.38,-461\"/>\n",
       "<text text-anchor=\"start\" x=\"14.38\" y=\"-484\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"11.38\" y=\"-472.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-482.25 48.62,-503.5 91.62,-503.5 91.62,-482.25 48.62,-482.25\"/>\n",
       "<text text-anchor=\"start\" x=\"58.12\" y=\"-489\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-482.25 91.62,-503.5 127.12,-503.5 127.12,-482.25 91.62,-482.25\"/>\n",
       "<text text-anchor=\"start\" x=\"96.62\" y=\"-489\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-461 48.62,-482.25 91.62,-482.25 91.62,-461 48.62,-461\"/>\n",
       "<text text-anchor=\"start\" x=\"53.62\" y=\"-467.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-461 91.62,-482.25 127.12,-482.25 127.12,-461 91.62,-461\"/>\n",
       "<text text-anchor=\"start\" x=\"96.62\" y=\"-467.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.75,-539.59C66.75,-532.32 66.75,-523.32 66.75,-514.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.25,-514.79 66.75,-504.79 63.25,-514.79 70.25,-514.79\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"127.12,-425 6.38,-425 6.38,-382.5 127.12,-382.5 127.12,-425\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6.38,-382.5 6.38,-425 48.62,-425 48.62,-382.5 6.38,-382.5\"/>\n",
       "<text text-anchor=\"start\" x=\"19.62\" y=\"-405.5\" font-family=\"Linux libertine\" font-size=\"10.00\">sub</text>\n",
       "<text text-anchor=\"start\" x=\"11.38\" y=\"-394.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-403.75 48.62,-425 91.62,-425 91.62,-403.75 48.62,-403.75\"/>\n",
       "<text text-anchor=\"start\" x=\"58.12\" y=\"-410.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-403.75 91.62,-425 127.12,-425 127.12,-403.75 91.62,-403.75\"/>\n",
       "<text text-anchor=\"start\" x=\"96.62\" y=\"-410.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-382.5 48.62,-403.75 91.62,-403.75 91.62,-382.5 48.62,-382.5\"/>\n",
       "<text text-anchor=\"start\" x=\"53.62\" y=\"-389.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-382.5 91.62,-403.75 127.12,-403.75 127.12,-382.5 91.62,-382.5\"/>\n",
       "<text text-anchor=\"start\" x=\"96.62\" y=\"-389.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.75,-461.15C66.75,-453.57 66.75,-444.75 66.75,-436.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.25,-436.49 66.75,-426.49 63.25,-436.49 70.25,-436.49\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"127.12,-346.5 6.38,-346.5 6.38,-304 127.12,-304 127.12,-346.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6.38,-304 6.38,-346.5 48.62,-346.5 48.62,-304 6.38,-304\"/>\n",
       "<text text-anchor=\"start\" x=\"18.5\" y=\"-327\" font-family=\"Linux libertine\" font-size=\"10.00\">pow</text>\n",
       "<text text-anchor=\"start\" x=\"11.38\" y=\"-315.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-325.25 48.62,-346.5 91.62,-346.5 91.62,-325.25 48.62,-325.25\"/>\n",
       "<text text-anchor=\"start\" x=\"58.12\" y=\"-332\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-325.25 91.62,-346.5 127.12,-346.5 127.12,-325.25 91.62,-325.25\"/>\n",
       "<text text-anchor=\"start\" x=\"96.62\" y=\"-332\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-304 48.62,-325.25 91.62,-325.25 91.62,-304 48.62,-304\"/>\n",
       "<text text-anchor=\"start\" x=\"53.62\" y=\"-310.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-304 91.62,-325.25 127.12,-325.25 127.12,-304 91.62,-304\"/>\n",
       "<text text-anchor=\"start\" x=\"96.62\" y=\"-310.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.75,-382.65C66.75,-375.07 66.75,-366.25 66.75,-357.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.25,-357.99 66.75,-347.99 63.25,-357.99 70.25,-357.99\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"127.12,-268 6.38,-268 6.38,-225.5 127.12,-225.5 127.12,-268\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6.38,-225.5 6.38,-268 48.62,-268 48.62,-225.5 6.38,-225.5\"/>\n",
       "<text text-anchor=\"start\" x=\"12.88\" y=\"-248.5\" font-family=\"Linux libertine\" font-size=\"10.00\">argmin</text>\n",
       "<text text-anchor=\"start\" x=\"11.38\" y=\"-237.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-246.75 48.62,-268 91.62,-268 91.62,-246.75 48.62,-246.75\"/>\n",
       "<text text-anchor=\"start\" x=\"58.12\" y=\"-253.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-246.75 91.62,-268 127.12,-268 127.12,-246.75 91.62,-246.75\"/>\n",
       "<text text-anchor=\"start\" x=\"96.62\" y=\"-253.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"48.62,-225.5 48.62,-246.75 91.62,-246.75 91.62,-225.5 48.62,-225.5\"/>\n",
       "<text text-anchor=\"start\" x=\"53.62\" y=\"-232.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.62,-225.5 91.62,-246.75 127.12,-246.75 127.12,-225.5 91.62,-225.5\"/>\n",
       "<text text-anchor=\"start\" x=\"100.75\" y=\"-232.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.75,-304.15C66.75,-296.57 66.75,-287.75 66.75,-279.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.25,-279.49 66.75,-269.49 63.25,-279.49 70.25,-279.49\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"133.5,-189.5 0,-189.5 0,-147 133.5,-147 133.5,-189.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-147 0,-189.5 63.25,-189.5 63.25,-147 0,-147\"/>\n",
       "<text text-anchor=\"start\" x=\"5\" y=\"-170\" font-family=\"Linux libertine\" font-size=\"10.00\">__getitem__</text>\n",
       "<text text-anchor=\"start\" x=\"15.5\" y=\"-158.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"63.25,-168.25 63.25,-189.5 106.25,-189.5 106.25,-168.25 63.25,-168.25\"/>\n",
       "<text text-anchor=\"start\" x=\"72.75\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"106.25,-168.25 106.25,-189.5 133.5,-189.5 133.5,-168.25 106.25,-168.25\"/>\n",
       "<text text-anchor=\"start\" x=\"111.25\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"63.25,-147 63.25,-168.25 106.25,-168.25 106.25,-147 63.25,-147\"/>\n",
       "<text text-anchor=\"start\" x=\"68.25\" y=\"-153.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"106.25,-147 106.25,-168.25 133.5,-168.25 133.5,-147 106.25,-147\"/>\n",
       "<text text-anchor=\"start\" x=\"111.25\" y=\"-153.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.75,-225.65C66.75,-218.07 66.75,-209.25 66.75,-200.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.25,-200.99 66.75,-190.99 63.25,-200.99 70.25,-200.99\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"123,-111 10.5,-111 10.5,-68.5 123,-68.5 123,-111\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"10.5,-68.5 10.5,-111 52.75,-111 52.75,-68.5 10.5,-68.5\"/>\n",
       "<text text-anchor=\"start\" x=\"18.5\" y=\"-91.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"15.5\" y=\"-80.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"52.75,-89.75 52.75,-111 95.75,-111 95.75,-89.75 52.75,-89.75\"/>\n",
       "<text text-anchor=\"start\" x=\"62.25\" y=\"-96.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"95.75,-89.75 95.75,-111 123,-111 123,-89.75 95.75,-89.75\"/>\n",
       "<text text-anchor=\"start\" x=\"100.75\" y=\"-96.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"52.75,-68.5 52.75,-89.75 95.75,-89.75 95.75,-68.5 52.75,-68.5\"/>\n",
       "<text text-anchor=\"start\" x=\"57.75\" y=\"-75.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"95.75,-68.5 95.75,-89.75 123,-89.75 123,-68.5 95.75,-68.5\"/>\n",
       "<text text-anchor=\"start\" x=\"100.75\" y=\"-75.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.75,-147.15C66.75,-139.57 66.75,-130.75 66.75,-122.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.25,-122.49 66.75,-112.49 63.25,-122.49 70.25,-122.49\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"112.38,-32.5 21.12,-32.5 21.12,0 112.38,0 112.38,-32.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"21.12,0 21.12,-32.5 88.12,-32.5 88.12,0 21.12,0\"/>\n",
       "<text text-anchor=\"start\" x=\"26.12\" y=\"-18\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"38.5\" y=\"-6.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"88.12,0 88.12,-32.5 112.38,-32.5 112.38,0 88.12,0\"/>\n",
       "<text text-anchor=\"start\" x=\"93.12\" y=\"-12.38\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.75,-68.83C66.75,-61.06 66.75,-52.03 66.75,-43.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.25,-43.81 66.75,-33.81 63.25,-43.81 70.25,-43.81\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1416c8980>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VQVAEQuantizeWithoutDerivative(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(1, 1)\n",
    "        self.codebook = nn.Parameter(torch.tensor([-5., -9., 0., 6., 9.]))\n",
    "        self.decoder = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_out = self.encoder(x)\n",
    "        l2_difference = (encoder_out - self.codebook) ** 2\n",
    "        nearest_index = torch.argmin(l2_difference, dim = -1)\n",
    "        # print(nearest_index)\n",
    "        decoder_input = self.codebook[nearest_index]\n",
    "        # print(decoder_input)\n",
    "        decoder_out = self.decoder(decoder_input)\n",
    "        return decoder_out\n",
    "\n",
    "q = VQVAEQuantizeWithoutDerivative()\n",
    "test = torch.ones(1).unsqueeze(0)\n",
    "out = q(test)\n",
    "# print(out)\n",
    "out.backward()\n",
    "model_graph = draw_graph(q, input_size = (1, 1))\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ccee7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Title: model Pages: 1 -->\n",
       "<svg width=\"232pt\" height=\"816pt\"\n",
       " viewBox=\"0.00 0.00 232.38 815.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 811.5)\">\n",
       "<title>model</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-811.5 228.38,-811.5 228.38,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"109.38,-807.5 15.88,-807.5 15.88,-775 109.38,-775 109.38,-807.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"15.88,-775 15.88,-807.5 76.88,-807.5 76.88,-775 15.88,-775\"/>\n",
       "<text text-anchor=\"start\" x=\"20.88\" y=\"-793\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"30.25\" y=\"-781.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"76.88,-775 76.88,-807.5 109.38,-807.5 109.38,-775 76.88,-775\"/>\n",
       "<text text-anchor=\"start\" x=\"81.88\" y=\"-787.38\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1)</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"123,-739 2.25,-739 2.25,-696.5 123,-696.5 123,-739\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2.25,-696.5 2.25,-739 44.5,-739 44.5,-696.5 2.25,-696.5\"/>\n",
       "<text text-anchor=\"start\" x=\"10.25\" y=\"-719.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"7.25\" y=\"-708.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"44.5,-717.75 44.5,-739 87.5,-739 87.5,-717.75 44.5,-717.75\"/>\n",
       "<text text-anchor=\"start\" x=\"54\" y=\"-724.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"87.5,-717.75 87.5,-739 123,-739 123,-717.75 87.5,-717.75\"/>\n",
       "<text text-anchor=\"start\" x=\"92.5\" y=\"-724.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"44.5,-696.5 44.5,-717.75 87.5,-717.75 87.5,-696.5 44.5,-696.5\"/>\n",
       "<text text-anchor=\"start\" x=\"49.5\" y=\"-703.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"87.5,-696.5 87.5,-717.75 123,-717.75 123,-696.5 87.5,-696.5\"/>\n",
       "<text text-anchor=\"start\" x=\"92.5\" y=\"-703.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.62,-775.09C62.62,-767.82 62.62,-758.82 62.62,-750.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.13,-750.29 62.63,-740.29 59.13,-750.29 66.13,-750.29\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"211,-660.5 90.25,-660.5 90.25,-618 211,-618 211,-660.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"90.25,-618 90.25,-660.5 132.5,-660.5 132.5,-618 90.25,-618\"/>\n",
       "<text text-anchor=\"start\" x=\"103.5\" y=\"-641\" font-family=\"Linux libertine\" font-size=\"10.00\">sub</text>\n",
       "<text text-anchor=\"start\" x=\"95.25\" y=\"-629.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"132.5,-639.25 132.5,-660.5 175.5,-660.5 175.5,-639.25 132.5,-639.25\"/>\n",
       "<text text-anchor=\"start\" x=\"142\" y=\"-646\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"175.5,-639.25 175.5,-660.5 211,-660.5 211,-639.25 175.5,-639.25\"/>\n",
       "<text text-anchor=\"start\" x=\"180.5\" y=\"-646\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"132.5,-618 132.5,-639.25 175.5,-639.25 175.5,-618 132.5,-618\"/>\n",
       "<text text-anchor=\"start\" x=\"137.5\" y=\"-624.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"175.5,-618 175.5,-639.25 211,-639.25 211,-618 175.5,-618\"/>\n",
       "<text text-anchor=\"start\" x=\"180.5\" y=\"-624.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M85.75,-696.65C95.87,-687.85 107.92,-677.38 118.87,-667.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"120.96,-670.68 126.21,-661.47 116.37,-665.39 120.96,-670.68\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"194.12,-346.5 53.12,-346.5 53.12,-304 194.12,-304 194.12,-346.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"53.12,-304 53.12,-346.5 95.38,-346.5 95.38,-304 53.12,-304\"/>\n",
       "<text text-anchor=\"start\" x=\"66.38\" y=\"-327\" font-family=\"Linux libertine\" font-size=\"10.00\">sub</text>\n",
       "<text text-anchor=\"start\" x=\"58.12\" y=\"-315.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"95.38,-325.25 95.38,-346.5 138.38,-346.5 138.38,-325.25 95.38,-325.25\"/>\n",
       "<text text-anchor=\"start\" x=\"104.88\" y=\"-332\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"138.38,-325.25 138.38,-346.5 194.12,-346.5 194.12,-325.25 138.38,-325.25\"/>\n",
       "<text text-anchor=\"start\" x=\"143.38\" y=\"-332\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,), (1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"95.38,-304 95.38,-325.25 138.38,-325.25 138.38,-304 95.38,-304\"/>\n",
       "<text text-anchor=\"start\" x=\"100.38\" y=\"-310.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"138.38,-304 138.38,-325.25 194.12,-325.25 194.12,-304 138.38,-304\"/>\n",
       "<text text-anchor=\"start\" x=\"153.5\" y=\"-310.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;6 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.62,-696.69C62.62,-667.14 62.63,-610.19 62.62,-561.75 62.62,-561.75 62.62,-561.75 62.62,-481.25 62.62,-436.56 63.58,-423.39 81.62,-382.5 85.81,-373.02 91.85,-363.64 98.04,-355.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.65,-357.67 104.08,-347.64 95.15,-353.34 100.65,-357.67\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"137.25,-189.5 0,-189.5 0,-147 137.25,-147 137.25,-189.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-147 0,-189.5 42.25,-189.5 42.25,-147 0,-147\"/>\n",
       "<text text-anchor=\"start\" x=\"13.25\" y=\"-170\" font-family=\"Linux libertine\" font-size=\"10.00\">add</text>\n",
       "<text text-anchor=\"start\" x=\"5\" y=\"-158.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"42.25,-168.25 42.25,-189.5 85.25,-189.5 85.25,-168.25 42.25,-168.25\"/>\n",
       "<text text-anchor=\"start\" x=\"51.75\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"85.25,-168.25 85.25,-189.5 137.25,-189.5 137.25,-168.25 85.25,-168.25\"/>\n",
       "<text text-anchor=\"start\" x=\"90.25\" y=\"-175\" font-family=\"Linux libertine\" font-size=\"10.00\">2 x (1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"42.25,-147 42.25,-168.25 85.25,-168.25 85.25,-147 42.25,-147\"/>\n",
       "<text text-anchor=\"start\" x=\"47.25\" y=\"-153.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"85.25,-147 85.25,-168.25 137.25,-168.25 137.25,-147 85.25,-147\"/>\n",
       "<text text-anchor=\"start\" x=\"98.5\" y=\"-153.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;8 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.38,-696.58C43.2,-667.36 24.63,-611.34 24.62,-561.75 24.62,-561.75 24.62,-561.75 24.62,-324.25 24.62,-279.66 41.69,-230.49 54.56,-199.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"57.73,-201.25 58.48,-190.68 51.3,-198.47 57.73,-201.25\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"212,-582 91.25,-582 91.25,-539.5 212,-539.5 212,-582\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91.25,-539.5 91.25,-582 133.5,-582 133.5,-539.5 91.25,-539.5\"/>\n",
       "<text text-anchor=\"start\" x=\"103.38\" y=\"-562.5\" font-family=\"Linux libertine\" font-size=\"10.00\">pow</text>\n",
       "<text text-anchor=\"start\" x=\"96.25\" y=\"-551.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"133.5,-560.75 133.5,-582 176.5,-582 176.5,-560.75 133.5,-560.75\"/>\n",
       "<text text-anchor=\"start\" x=\"143\" y=\"-567.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"176.5,-560.75 176.5,-582 212,-582 212,-560.75 176.5,-560.75\"/>\n",
       "<text text-anchor=\"start\" x=\"181.5\" y=\"-567.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"133.5,-539.5 133.5,-560.75 176.5,-560.75 176.5,-539.5 133.5,-539.5\"/>\n",
       "<text text-anchor=\"start\" x=\"138.5\" y=\"-546.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"176.5,-539.5 176.5,-560.75 212,-560.75 212,-539.5 176.5,-539.5\"/>\n",
       "<text text-anchor=\"start\" x=\"181.5\" y=\"-546.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M150.89,-618.15C150.99,-610.57 151.1,-601.75 151.21,-593.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"154.71,-593.54 151.34,-583.49 147.71,-593.45 154.71,-593.54\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"214,-503.5 93.25,-503.5 93.25,-461 214,-461 214,-503.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"93.25,-461 93.25,-503.5 135.5,-503.5 135.5,-461 93.25,-461\"/>\n",
       "<text text-anchor=\"start\" x=\"99.75\" y=\"-484\" font-family=\"Linux libertine\" font-size=\"10.00\">argmin</text>\n",
       "<text text-anchor=\"start\" x=\"98.25\" y=\"-472.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"135.5,-482.25 135.5,-503.5 178.5,-503.5 178.5,-482.25 135.5,-482.25\"/>\n",
       "<text text-anchor=\"start\" x=\"145\" y=\"-489\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"178.5,-482.25 178.5,-503.5 214,-503.5 214,-482.25 178.5,-482.25\"/>\n",
       "<text text-anchor=\"start\" x=\"183.5\" y=\"-489\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 5) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"135.5,-461 135.5,-482.25 178.5,-482.25 178.5,-461 135.5,-461\"/>\n",
       "<text text-anchor=\"start\" x=\"140.5\" y=\"-467.75\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"178.5,-461 178.5,-482.25 214,-482.25 214,-461 178.5,-461\"/>\n",
       "<text text-anchor=\"start\" x=\"187.62\" y=\"-467.75\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M152.15,-539.65C152.35,-532.07 152.58,-523.25 152.8,-514.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.29,-515.08 153.06,-504.99 149.3,-514.9 156.29,-515.08\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"224.38,-425 90.88,-425 90.88,-382.5 224.38,-382.5 224.38,-425\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"90.88,-382.5 90.88,-425 154.12,-425 154.12,-382.5 90.88,-382.5\"/>\n",
       "<text text-anchor=\"start\" x=\"95.88\" y=\"-405.5\" font-family=\"Linux libertine\" font-size=\"10.00\">__getitem__</text>\n",
       "<text text-anchor=\"start\" x=\"106.38\" y=\"-394.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"154.12,-403.75 154.12,-425 197.12,-425 197.12,-403.75 154.12,-403.75\"/>\n",
       "<text text-anchor=\"start\" x=\"163.62\" y=\"-410.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"197.12,-403.75 197.12,-425 224.38,-425 224.38,-403.75 197.12,-403.75\"/>\n",
       "<text text-anchor=\"start\" x=\"202.12\" y=\"-410.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"154.12,-382.5 154.12,-403.75 197.12,-403.75 197.12,-382.5 154.12,-382.5\"/>\n",
       "<text text-anchor=\"start\" x=\"159.12\" y=\"-389.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"197.12,-382.5 197.12,-403.75 224.38,-403.75 224.38,-382.5 197.12,-382.5\"/>\n",
       "<text text-anchor=\"start\" x=\"202.12\" y=\"-389.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1,) </text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.68,-461.15C155.07,-453.57 155.53,-444.75 155.97,-436.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.46,-436.66 156.49,-426.49 152.47,-436.3 159.46,-436.66\"/>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.69,-382.65C145.21,-374.81 141.13,-365.64 137.29,-357\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"140.49,-355.58 133.23,-347.86 134.09,-358.42 140.49,-355.58\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"aliceblue\" stroke=\"none\" points=\"178,-268 57.25,-268 57.25,-225.5 178,-225.5 178,-268\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"57.25,-225.5 57.25,-268 99.5,-268 99.5,-225.5 57.25,-225.5\"/>\n",
       "<text text-anchor=\"start\" x=\"63.75\" y=\"-248.5\" font-family=\"Linux libertine\" font-size=\"10.00\">detach</text>\n",
       "<text text-anchor=\"start\" x=\"62.25\" y=\"-237.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"99.5,-246.75 99.5,-268 142.5,-268 142.5,-246.75 99.5,-246.75\"/>\n",
       "<text text-anchor=\"start\" x=\"109\" y=\"-253.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"142.5,-246.75 142.5,-268 178,-268 178,-246.75 142.5,-246.75\"/>\n",
       "<text text-anchor=\"start\" x=\"147.5\" y=\"-253.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"99.5,-225.5 99.5,-246.75 142.5,-246.75 142.5,-225.5 99.5,-225.5\"/>\n",
       "<text text-anchor=\"start\" x=\"104.5\" y=\"-232.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"142.5,-225.5 142.5,-246.75 178,-246.75 178,-225.5 142.5,-225.5\"/>\n",
       "<text text-anchor=\"start\" x=\"147.5\" y=\"-232.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122.05,-304.15C121.45,-296.57 120.76,-287.75 120.1,-279.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"123.6,-279.19 119.33,-269.49 116.62,-279.73 123.6,-279.19\"/>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M104.75,-225.65C99.56,-217.55 93.46,-208.02 87.77,-199.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.74,-197.29 82.4,-190.76 84.85,-201.06 90.74,-197.29\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"129,-111 8.25,-111 8.25,-68.5 129,-68.5 129,-111\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8.25,-68.5 8.25,-111 50.5,-111 50.5,-68.5 8.25,-68.5\"/>\n",
       "<text text-anchor=\"start\" x=\"16.25\" y=\"-91.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n",
       "<text text-anchor=\"start\" x=\"13.25\" y=\"-80.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:1</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"50.5,-89.75 50.5,-111 93.5,-111 93.5,-89.75 50.5,-89.75\"/>\n",
       "<text text-anchor=\"start\" x=\"60\" y=\"-96.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"93.5,-89.75 93.5,-111 129,-111 129,-89.75 93.5,-89.75\"/>\n",
       "<text text-anchor=\"start\" x=\"98.5\" y=\"-96.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"50.5,-68.5 50.5,-89.75 93.5,-89.75 93.5,-68.5 50.5,-68.5\"/>\n",
       "<text text-anchor=\"start\" x=\"55.5\" y=\"-75.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"93.5,-68.5 93.5,-89.75 129,-89.75 129,-68.5 93.5,-68.5\"/>\n",
       "<text text-anchor=\"start\" x=\"98.5\" y=\"-75.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1) </text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.62,-147.15C68.62,-139.57 68.62,-130.75 68.62,-122.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"72.13,-122.49 68.63,-112.49 65.13,-122.49 72.13,-122.49\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"lightyellow\" stroke=\"none\" points=\"118.38,-32.5 18.88,-32.5 18.88,0 118.38,0 118.38,-32.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"18.88,0 18.88,-32.5 85.88,-32.5 85.88,0 18.88,0\"/>\n",
       "<text text-anchor=\"start\" x=\"23.88\" y=\"-18\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n",
       "<text text-anchor=\"start\" x=\"36.25\" y=\"-6.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"85.88,0 85.88,-32.5 118.38,-32.5 118.38,0 85.88,0\"/>\n",
       "<text text-anchor=\"start\" x=\"90.88\" y=\"-12.38\" font-family=\"Linux libertine\" font-size=\"10.00\">(1, 1)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.62,-68.83C68.62,-61.06 68.62,-52.03 68.62,-43.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"72.13,-43.81 68.63,-33.81 65.13,-43.81 72.13,-43.81\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x126766d50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VQVAEQuantizeWithDerivative(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(1, 1)\n",
    "        self.codebook = nn.Parameter(torch.tensor([-5., -9., 0., 6., 9.]))\n",
    "        self.decoder = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_out = self.encoder(x)\n",
    "        l2_difference = (encoder_out - self.codebook) ** 2\n",
    "        nearest_index = torch.argmin(l2_difference, dim = -1)\n",
    "        # print(nearest_index)\n",
    "        decoder_input = self.codebook[nearest_index]\n",
    "        # print(decoder_input)\n",
    "        decoder_input = encoder_out + (decoder_input - encoder_out).detach()\n",
    "        decoder_out = self.decoder(decoder_input)\n",
    "        return decoder_out\n",
    "\n",
    "q = VQVAEQuantizeWithDerivative()\n",
    "test = torch.ones(1).unsqueeze(0)\n",
    "out = q(test)\n",
    "# print(out)\n",
    "out.backward()\n",
    "model_graph = draw_graph(q, input_size = (1, 1))\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c7b1877a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0109,  0.1786, -0.0845,  ..., -0.1966,  0.0871,  0.2342],\n",
       "         [-0.1458, -0.1642, -0.0300,  ..., -0.2130, -0.1846, -0.1496],\n",
       "         [-0.0961,  0.2081,  0.0385,  ...,  0.0300, -0.0332,  0.0712],\n",
       "         ...,\n",
       "         [-0.1837,  0.0764, -0.1859,  ...,  0.1913,  0.0171,  0.1789],\n",
       "         [ 0.2107,  0.0715,  0.0630,  ...,  0.0220, -0.2299,  0.2445],\n",
       "         [-0.2481, -0.0982,  0.2325,  ..., -0.1347, -0.1603, -0.2351]],\n",
       "        grad_fn=<MmBackward0>),\n",
       " tensor([19, 53, 63,  ...,  8, 24,  6]),\n",
       " tensor(59.4609))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorQuantizeImage(nn.Module):\n",
    "    def __init__(self, codeBookDim = 64, embeddingDim = 32, decay = 0.99, eps = 1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.codeBookDim = codeBookDim\n",
    "        self.embeddingDim = embeddingDim\n",
    "        self.decay = decay\n",
    "        self.eps = eps\n",
    "\n",
    "        self.codebook = nn.Embedding(codeBookDim, embeddingDim)\n",
    "        nn.init.xavier_uniform_(self.codebook.weight.data)\n",
    "\n",
    "        self.register_buffer('ema_Count', torch.zeros(codeBookDim))\n",
    "        self.register_buffer('ema_Weight', self.codebook.weight.data.clone())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_reshaped = x.view(-1, self.embeddingDim)\n",
    "\n",
    "        distance = (torch.sum(x_reshaped**2, dim=1, keepdim=True) \n",
    "                    + torch.sum(self.codebook.weight**2, dim=1)\n",
    "                    - 2 * torch.matmul(x_reshaped, self.codebook.weight.t()))\n",
    "        \n",
    "        encoding_indices = torch.argmin(distance, dim=1) \n",
    "        encodings = Fn.one_hot(encoding_indices, self.codeBookDim).type(x_reshaped.dtype)\n",
    "        quantized = torch.matmul(encodings, self.codebook.weight)\n",
    "\n",
    "        if self.training:\n",
    "            self.ema_Count = self.decay * self.ema_Count + (1 - self.decay) * torch.sum(encodings, 0)\n",
    "            \n",
    "            x_reshaped_sum = torch.matmul(encodings.t(), x_reshaped.detach())\n",
    "            self.ema_Weight = self.decay * self.ema_Weight + (1 - self.decay) * x_reshaped_sum\n",
    "            \n",
    "            n = torch.clamp(self.ema_Count, min=self.eps)\n",
    "            updated_embeddings = self.ema_Weight / n.unsqueeze(1)\n",
    "            self.codebook.weight.data.copy_(updated_embeddings)\n",
    "\n",
    "        \n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "\n",
    "        # quantized = x + (quantized - x).detach()\n",
    "\n",
    "        return quantized, encoding_indices, perplexity\n",
    "        \n",
    "        \n",
    "vq = VectorQuantizeImage(codeBookDim=64,embeddingDim=32)\n",
    "rand = torch.randn(1024,32)\n",
    "vq(rand)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "866b16b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 32, 16, 16]),\n",
       " torch.Size([32, 1, 64, 64]),\n",
       " tensor(0.1375, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.1375, grad_fn=<MseLossBackward0>),\n",
       " torch.Size([8192]),\n",
       " tensor(26.4422))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VecQVAE(nn.Module):\n",
    "    def __init__(self, inChannels = 1, hiddenDim = 32, codeBookdim = 128, embedDim = 128):\n",
    "        super().__init__()\n",
    "        self.inChannels = inChannels\n",
    "        self.hiddenDim = hiddenDim\n",
    "        self.codeBookdim = codeBookdim\n",
    "        self.embedDim = embedDim\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(inChannels, hiddenDim, 4, 2, 1), \n",
    "            nn.BatchNorm2d(hiddenDim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(hiddenDim, hiddenDim, 3, 1, 1),\n",
    "            nn.BatchNorm2d(hiddenDim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(hiddenDim, 2 * hiddenDim, 4, 2, 1),\n",
    "            nn.BatchNorm2d(2 * hiddenDim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(2 * hiddenDim, 2 * hiddenDim, 3, 1, 1),\n",
    "            nn.BatchNorm2d(2 * hiddenDim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(2 * hiddenDim, embedDim, 1),\n",
    "        )\n",
    "\n",
    "        self.vector_quantize = VectorQuantizeImage(codeBookDim=codeBookdim,embeddingDim=embedDim)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(embedDim, 2 * hiddenDim, 4, 2, 1),\n",
    "            nn.BatchNorm2d(2 * hiddenDim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(2 * hiddenDim, 2 * hiddenDim, 3, 1, 1),\n",
    "            nn.BatchNorm2d(2 * hiddenDim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(2 * hiddenDim, hiddenDim, 4, 2, 1),\n",
    "            nn.BatchNorm2d(hiddenDim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(hiddenDim, hiddenDim, 3, 1, 1),\n",
    "            nn.BatchNorm2d(hiddenDim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(hiddenDim, inChannels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encodeImage(self, x):\n",
    "        encodedOut = self.encoder(x)\n",
    "        return encodedOut;\n",
    "\n",
    "    def decodeImage(self, quantized_vector):\n",
    "        decodedOut = self.decoder(quantized_vector)\n",
    "        return decodedOut\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, inChannels, height, width = x.shape\n",
    "        encodedOut = self.encodeImage(x)\n",
    "        batch_size, encoded_channel, encoded_height, encoded_width = encodedOut.shape\n",
    "        \n",
    "        # print(f\"Encoded Shape: {encodedOut.shape}\")\n",
    "\n",
    "        \n",
    "        vectorize_input = rearrange(encodedOut, 'b c h w -> (b h w) c')\n",
    "        quantized_vectors, encoding_indices, perplexity  = self.vector_quantize(vectorize_input)\n",
    "        codebook_loss = Fn.mse_loss(vectorize_input.detach(), quantized_vectors)\n",
    "        commitment_loss = Fn.mse_loss(vectorize_input, quantized_vectors.detach())\n",
    "\n",
    "        quantized_vectors = vectorize_input + (quantized_vectors - vectorize_input).detach()\n",
    "        # print(f\"CodeBook Loss: {codebook_loss} , Commitment Loss: {commitment_loss}\")\n",
    "        # print(f\"Quantized SHape: {quantized_vectors.shape}\")\n",
    "\n",
    "        decoder_input = rearrange(quantized_vectors, '(b h w) d -> b d h w', d = encoded_channel, h = encoded_height, w = encoded_width)\n",
    "        # print(f\"Decoded Input SHape: {decoder_input.shape}\")\n",
    "        decodedOut = self.decodeImage(decoder_input)\n",
    "\n",
    "        # print(f\"Decoded SHape: {decodedOut.shape}\")\n",
    "        \n",
    "        return decoder_input, decodedOut, codebook_loss, commitment_loss, encoding_indices, perplexity\n",
    "\n",
    "VQ = VecQVAE(inChannels = 1, hiddenDim = 128, codeBookdim = 64, embedDim = 32)\n",
    "test = torch.randn(32, 1, 64, 64)\n",
    "quantized_latents, decoderOut, codebook_loss, commitment_loss, encoding_indices, perplexity = VQ(test)\n",
    "quantized_latents.shape, decoderOut.shape, codebook_loss, commitment_loss, encoding_indices.shape, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be677e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 10000, 64, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 20, 1, 64, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"data/MovingMNIST/mnist_test_seq.npy\")\n",
    "print(data.shape)\n",
    "data = np.transpose(data, (1, 0, 2, 3))\n",
    "data = torch.from_numpy(data)\n",
    "data = data.unsqueeze(2)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe654757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64, 64]), torch.Size([1, 64, 64]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MakeFrameDataset(Dataset):\n",
    "    def __init__(self, video, input_length=10, output_length=10):\n",
    "        super().__init__()\n",
    "        num_videos, num_frames, C, H, W = video.shape\n",
    "        self.frames = video.reshape(-1, C, H, W)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.frames.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame = self.frames[idx]\n",
    "        return frame, frame\n",
    "    \n",
    "test = torch.randn(32, 20, 1, 64, 64)\n",
    "out = MakeFrameDataset(test)\n",
    "x, y = out.__getitem__(0)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21a30c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeBookdim = 64\n",
    "embedDim = 32\n",
    "hiddenDim = 128\n",
    "inChannels = 1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torchDataset = MakeFrameDataset(data)\n",
    "dataloader = DataLoader(torchDataset, batch_size=64, shuffle = True)\n",
    "modelA = VecQVAE(inChannels = inChannels, hiddenDim = hiddenDim, codeBookdim = codeBookdim, embedDim = embedDim).to(device)\n",
    "lossFn = nn.MSELoss()#VecVAELoss(betaValue = 0.25)\n",
    "optimizerA = torch.optim.Adam([\n",
    "                    {'params': modelA.encoder.parameters(), 'lr': 2e-4},\n",
    "                    {'params': modelA.decoder.parameters(), 'lr': 2e-4},\n",
    "                    {'params': modelA.vector_quantize.parameters(), 'lr': 1e-4}\n",
    "                ], weight_decay=1e-5)\n",
    "schedulerA = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                optimizerA, T_0=10, T_mult=2, eta_min=1e-6\n",
    "            )\n",
    "\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e3d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelValA = torch.load(\"./model/VQVAE/vqvae.pt\", map_location=torch.device('cpu'))\n",
    "# modelA.load_state_dict(modelValA)\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "    modelA.train()\n",
    "    reconstruct_loss = 0.0\n",
    "    codeb_loss = 0.0\n",
    "    commit_loss = 0.0\n",
    "    \n",
    "    vqvaeloss = 0.0\n",
    "    loop = tqdm(dataloader, f\"{each_epoch}/{epochs}\")\n",
    "\n",
    "    for X, Y in loop:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        quantized_latents, decoderOut, codebook_loss, commitment_loss, encoding_indices, perplexity = modelA(X)\n",
    "        reconstruction_loss = torch.mean((Y - decoderOut)**2)\n",
    "        \n",
    "        perplexity_loss = -torch.log(perplexity + 1e-10)\n",
    "        loss = reconstruction_loss + codebook_loss + 0.25 * commitment_loss + 0.01 * perplexity_loss\n",
    "        vqvaeloss += loss.item()\n",
    "\n",
    "        \n",
    "        reconstruct_loss += reconstruction_loss.item()\n",
    "        codeb_loss += codebook_loss.item()\n",
    "        commit_loss += commitment_loss.item()\n",
    "        \n",
    "        optimizerA.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(modelA.parameters(), max_norm=1.0)\n",
    "        optimizerA.step()\n",
    "        loop.set_postfix({\"TotalL\": f\"{vqvaeloss}\", \"ReconsL\": f\"{reconstruct_loss}\", \"CodeL\":f\"{codeb_loss}\",\n",
    "                          \"CommitL\":f\"{commitment_loss}\", \"Perplexity\":f\"{perplexity}\"})\n",
    "    #     break\n",
    "    # break\n",
    "\n",
    "    vqvaeloss /= len(dataloader)   \n",
    "    reconstruct_loss /= len(dataloader)   \n",
    "    codeb_loss /= len(dataloader)   \n",
    "    commit_loss /= len(dataloader)   \n",
    "    torch.save(modelA.state_dict(), \"./model/VQVAE/vqvae.pt\")\n",
    "    wandb.log({\n",
    "        \"Epoch\": each_epoch,\n",
    "        \"VQVAE LR\": optimizerA.param_groups[0]['lr'],\n",
    "        \"VQVAE Loss\": vqvaeloss,\n",
    "        \"Reconstruction Loss\": reconstruct_loss,\n",
    "        \"Codebook Loss\": codeb_loss,\n",
    "        \"Commitment Loss\": commit_loss\n",
    "        # \"Perplexity\": perplexity\n",
    "    })\n",
    "    schedulerA.step()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cd0d269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelValA = torch.load(\"./model/VQVAE/vqvae.pt\", map_location=torch.device('cpu'))\n",
    "modelA.load_state_dict(modelValA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b424cea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0, 0, ...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8a57839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_image = torch.randn(1, 1, 64, 64)\n",
    "temp_image = data[0, 10, ...].squeeze()\n",
    "image_np = temp_image.numpy().astype(np.uint8)\n",
    "image = Image.fromarray(image_np, mode='L') \n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"Image from Tensor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79dac303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 64])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data[0, 10, ...].unsqueeze(0)/255.0\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68337e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 64])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"image.png\")\n",
    "img = img.convert(\"L\")\n",
    "\n",
    "img = img.resize((64, 64))\n",
    "\n",
    "img_array = np.array(img)#.reshape((1, 64, 64))\n",
    "img_array = np.array(img).astype(np.float32)  # shape: (64, 64)\n",
    "\n",
    "img_array.shape\n",
    "\n",
    "tensor = torch.from_numpy(img_array).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "plt.imshow(img_array, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"Image from Tensor\")\n",
    "plt.show()\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a12f2a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_image, _, _, _, _ = modelA(tensor/255.0)\n",
    "out_image = modelA.decodeImage(out_image)\n",
    "out_image = out_image.squeeze()\n",
    "image_np = (out_image * 255).clamp(0, 255).byte().cpu().numpy()\n",
    "\n",
    "image = Image.fromarray(image_np, mode='L') \n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"Image from Tensor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81659969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6043f395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429479c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026557f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d85b86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2560])\n"
     ]
    }
   ],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size=512, seq_length = 10, embed_dim=256, num_heads=4, feed_forward_dim=512):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, seq_length, embed_dim, embed_dim))\n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=feed_forward_dim,\n",
    "            dropout=0.1,\n",
    "            batch_first=True  # Use batch-first format\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=6)\n",
    "        \n",
    "        self.output_layer = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch, features = x.shape\n",
    "        x = rearrange(x, 'b (s e) -> b s e', e = self.embed_dim, s = self.seq_length)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x = x + self.positional_encoding\n",
    "        x = rearrange(x, 'b s e d -> b (s e) d', e = self.embed_dim, s = self.seq_length)\n",
    "        x = self.encoder(x)\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        x = rearrange(x, 'b s e -> b (s e)')\n",
    "        \n",
    "        return x\n",
    "\n",
    " \n",
    "tr = Transformer()\n",
    "test = torch.randint(0, 10, (2, 2560))\n",
    "\n",
    "out = tr(test)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad09de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/q2s37ndx6tg3lpzp3vp8xk_r0000gn/T/ipykernel_11585/2549432269.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(input_frames, dtype=torch.float32),\n",
      "/var/folders/y8/q2s37ndx6tg3lpzp3vp8xk_r0000gn/T/ipykernel_11585/2549432269.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(output_frames, dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 1, 4, 4]), torch.Size([10, 1, 4, 4]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MakeVideoDataset(Dataset):\n",
    "    def __init__(self, video, input_length=10, output_length=10):\n",
    "        super().__init__()\n",
    "        self.video = video\n",
    "        self.input_length = input_length\n",
    "        self.output_length = output_length\n",
    "        self.batch_size, self.seq_len, _, _, _ = video.shape\n",
    "\n",
    "        self.samples_per_video = self.seq_len - input_length - output_length + 1\n",
    "        self.total_samples = self.batch_size * self.samples_per_video\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_idx = idx // self.samples_per_video\n",
    "        time_idx = idx % self.samples_per_video\n",
    "\n",
    "        input_frames = self.video[batch_idx, time_idx:time_idx + self.input_length]\n",
    "        output_frames = self.video[batch_idx, time_idx + self.input_length:time_idx + self.input_length + self.output_length]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(input_frames, dtype=torch.float32),\n",
    "            torch.tensor(output_frames, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "    \n",
    "    \n",
    "test = torch.randn(32, 20, 1, 4, 4)\n",
    "out = MakeVideoDataset(test)\n",
    "x, y = out.__getitem__(0)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2faea622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 10000, 64, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 20, 1, 64, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"data/MovingMNIST/mnist_test_seq.npy\")\n",
    "print(data.shape)\n",
    "data = np.transpose(data, (1, 0, 2, 3))\n",
    "data = torch.from_numpy(data)\n",
    "data = data.unsqueeze(2)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2687cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.cuda.is_available() else 'cpu')\n",
    "torchDataset = MakeVideoDataset(data)\n",
    "dataloader = DataLoader(torchDataset, batch_size=8, shuffle = True)\n",
    "\n",
    "transformer_celoss =nn.CrossEntropyLoss()\n",
    "modelA = Transformer().to(device)\n",
    "modelB = VecQVAE().to(device)\n",
    "\n",
    "optimizerA = optim.AdamW(modelA.parameters(), lr=5e-5)\n",
    "optimizerB = optim.Adam(modelB.parameters(), lr=2e-4)\n",
    "schedulerA = StepLR(optimizerA, step_size=10, gamma=0.5)  \n",
    "schedulerB = StepLR(optimizerB, step_size=20, gamma=0.7)  \n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7972105a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0/50:   0%|          | 0/1250 [00:00<?, ?it/s]/var/folders/y8/q2s37ndx6tg3lpzp3vp8xk_r0000gn/T/ipykernel_11585/2549432269.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(input_frames, dtype=torch.float32),\n",
      "/var/folders/y8/q2s37ndx6tg3lpzp3vp8xk_r0000gn/T/ipykernel_11585/2549432269.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(output_frames, dtype=torch.float32)\n",
      "0/50:   0%|          | 0/1250 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m outputCodeboobIndices = torch.cat(output_indices, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# print(inputCodeboobIndices.shape)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m predX = \u001b[43mmodelA\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputCodeboobIndices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# y = modelA(outputCodeboobIndices)\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# print(predX.shape, inputCodeboobIndices.shape, outputCodeboobIndices.shape)\u001b[39;00m\n\u001b[32m     36\u001b[39m predX = rearrange(predX, \u001b[33m'\u001b[39m\u001b[33mb (d l) -> b d l\u001b[39m\u001b[33m'\u001b[39m, l = \u001b[32m10\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     28\u001b[39m x = x + \u001b[38;5;28mself\u001b[39m.positional_encoding\n\u001b[32m     29\u001b[39m x = rearrange(x, \u001b[33m'\u001b[39m\u001b[33mb s e d -> b (s e) d\u001b[39m\u001b[33m'\u001b[39m, e = \u001b[38;5;28mself\u001b[39m.embed_dim, s = \u001b[38;5;28mself\u001b[39m.seq_length)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m x = \u001b[38;5;28mself\u001b[39m.output_layer(x)\n\u001b[32m     33\u001b[39m x = rearrange(x, \u001b[33m'\u001b[39m\u001b[33mb s e -> b (s e)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/transformer.py:517\u001b[39m, in \u001b[36mTransformerEncoder.forward\u001b[39m\u001b[34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    514\u001b[39m is_causal = _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     output = \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[32m    525\u001b[39m     output = output.to_padded_tensor(\u001b[32m0.0\u001b[39m, src.size())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/transformer.py:920\u001b[39m, in \u001b[36mTransformerEncoderLayer.forward\u001b[39m\u001b[34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    916\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m._ff_block(\u001b[38;5;28mself\u001b[39m.norm2(x))\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    918\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm1(\n\u001b[32m    919\u001b[39m         x\n\u001b[32m--> \u001b[39m\u001b[32m920\u001b[39m         + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    921\u001b[39m     )\n\u001b[32m    922\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm2(x + \u001b[38;5;28mself\u001b[39m._ff_block(x))\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/transformer.py:934\u001b[39m, in \u001b[36mTransformerEncoderLayer._sa_block\u001b[39m\u001b[34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[39m\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sa_block\u001b[39m(\n\u001b[32m    928\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    929\u001b[39m     x: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    932\u001b[39m     is_causal: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    933\u001b[39m ) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m934\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    943\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout1(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/modules/activation.py:1373\u001b[39m, in \u001b[36mMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   1347\u001b[39m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[32m   1348\u001b[39m         query,\n\u001b[32m   1349\u001b[39m         key,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1370\u001b[39m         is_causal=is_causal,\n\u001b[32m   1371\u001b[39m     )\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m     attn_output, attn_output_weights = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m), attn_output_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/pytorch_env/lib/python3.13/site-packages/torch/nn/functional.py:6410\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   6407\u001b[39m k = k.view(bsz, num_heads, src_len, head_dim)\n\u001b[32m   6408\u001b[39m v = v.view(bsz, num_heads, src_len, head_dim)\n\u001b[32m-> \u001b[39m\u001b[32m6410\u001b[39m attn_output = \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   6411\u001b[39m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\n\u001b[32m   6412\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6413\u001b[39m attn_output = (\n\u001b[32m   6414\u001b[39m     attn_output.permute(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m).contiguous().view(bsz * tgt_len, embed_dim)\n\u001b[32m   6415\u001b[39m )\n\u001b[32m   6417\u001b[39m attn_output = linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for each_epoch in range(epochs):\n",
    "\n",
    "    loop = tqdm(dataloader, f\"{each_epoch}/{epochs}\")\n",
    "    for datapoint in loop:\n",
    "        # print(datapoint[0].shape, datapoint[1].shape)\n",
    "        datapoint[0] = datapoint[0]/255.0\n",
    "        datapoint[1] = datapoint[1]/255.0\n",
    "\n",
    "        input_indices = []\n",
    "        output_indices = []\n",
    "        vqvaeloss = 0.0\n",
    "        transformer_loss = 0.0\n",
    "        totalLoss = 0.0\n",
    "\n",
    "        for each_frame_index in range(datapoint[0].shape[1]):\n",
    "            each_input_frame = datapoint[0][:, each_frame_index, ...]\n",
    "            each_input_frame = each_input_frame.to(device)\n",
    "            out, ez, qz, inputindex = modelB(each_input_frame)\n",
    "            vqvaeloss += VecQVAELoss(each_input_frame, out, ez, qz)\n",
    "\n",
    "            each_output_frame = datapoint[1][:, each_frame_index, ...]\n",
    "            each_output_frame = each_output_frame.to(device)\n",
    "            out, ez, qz, outputindex = modelB(each_output_frame)\n",
    "            vqvaeloss += VecQVAELoss(each_output_frame, out, ez, qz)\n",
    "\n",
    "            input_indices.append(inputindex)\n",
    "            output_indices.append(outputindex)\n",
    "\n",
    "        # print(vqvaeloss)\n",
    "        inputCodeboobIndices = torch.cat(input_indices, dim=-1)\n",
    "        outputCodeboobIndices = torch.cat(output_indices, dim=-1)\n",
    "        inputCodeboobIndices = inputCodeboobIndices.to(device)\n",
    "        outputCodeboobIndices = outputCodeboobIndices.to(device)\n",
    "\n",
    "        # print(inputCodeboobIndices.shape)\n",
    "        predX = modelA(inputCodeboobIndices)\n",
    "        # y = modelA(outputCodeboobIndices)\n",
    "        # print(predX.shape, inputCodeboobIndices.shape, outputCodeboobIndices.shape)\n",
    "        \n",
    "        predX = rearrange(predX, 'b (d l) -> b d l', l = 10)\n",
    "        outputCodeboobIndices = rearrange(outputCodeboobIndices, 'b (d l) -> b d l', l = 10)\n",
    "\n",
    "        loss = transformer_celoss(predX, outputCodeboobIndices.float())\n",
    "        # # transformer_loss += loss.item()\n",
    "\n",
    "        combined_loss = loss + vqvaeloss\n",
    "        \n",
    "\n",
    "        optimizerA.zero_grad()\n",
    "        optimizerB.zero_grad()\n",
    "\n",
    "        combined_loss.backward()\n",
    "\n",
    "        optimizerA.step()\n",
    "        optimizerB.step()\n",
    "        loop.set_postfix({\"VQVAE Loss\": f\"{vqvaeloss.item()}\", \" Transformer Loss\": f\"{loss.item()}\", \" Total Loss\": f\"{combined_loss.item()}\"})\n",
    "        \n",
    "    # if each_epoch % 5 == 0:\n",
    "    torch.save(modelA.state_dict(), \"./model/VQVAE/transformer.pt\")\n",
    "    torch.save(modelB.state_dict(), \"./model/VQVAE/vqvae.pt\")\n",
    "    wandb.log({\n",
    "        \"Epoch\": each_epoch,\n",
    "        \"VQVAE Loss\": vqvaeloss.item(),\n",
    "        \"Transformer Loss\": loss.item(),\n",
    "        \"Total Loss\": combined_loss.item(),\n",
    "        \"Transformer LR\" : optimizerA.param_groups[0]['lr'],\n",
    "        \"VQVAE LR\": optimizerB.param_groups[0]['lr']\n",
    "    })\n",
    "\n",
    "    schedulerA.step()\n",
    "    schedulerB.step()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbd09236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 20, 64, 64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"data/MovingMNIST/mnist_test_seq.npy\")\n",
    "data = np.transpose(data, (1, 0, 2, 3))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac07a0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/gif": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualizeData(sequence):\n",
    "\n",
    "    frames = [Image.fromarray((frame * 255).astype(np.uint8), mode='L') for frame in sequence]\n",
    "\n",
    "    buffer = BytesIO()\n",
    "    frames[0].save(\n",
    "        buffer,\n",
    "        format='GIF',\n",
    "        save_all=True,\n",
    "        append_images=frames[1:],\n",
    "        duration=100,\n",
    "        loop=0\n",
    "    )\n",
    "\n",
    "    buffer.seek(0)\n",
    "    display(IPyImage(data=buffer.getvalue()))\n",
    "\n",
    "visualizeData(data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e03ed97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelValA = torch.load(\"model/VQVAE/transformer.pt\", map_location=torch.device('mps'))\n",
    "modelA.load_state_dict(modelValA)\n",
    "\n",
    "modelValB = torch.load(\"model/VQVAE/vqvae.pt\", map_location=torch.device('mps'))\n",
    "modelB.load_state_dict(modelValB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e0c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_frame = torch.from_numpy(data[0, 10]/255.0)\n",
    "\n",
    "initial_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38bcd13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
