{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cefae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97384ec3",
   "metadata": {},
   "source": [
    "### VIT Reference\n",
    "Refer to (https://github.com/Ishushan02/Cervical-Cancer-Detection-Using-Vision-Transformer) for Vision Transformer block code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff58320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  1,  2,  3],\n",
      "          [ 4,  5,  6,  7],\n",
      "          [ 8,  9, 10, 11],\n",
      "          [12, 13, 14, 15]]],\n",
      "\n",
      "\n",
      "        [[[16, 17, 18, 19],\n",
      "          [20, 21, 22, 23],\n",
      "          [24, 25, 26, 27],\n",
      "          [28, 29, 30, 31]]]])\n",
      "tensor([[[[[[ 0,  1],\n",
      "            [ 4,  5]],\n",
      "\n",
      "           [[ 2,  3],\n",
      "            [ 6,  7]]],\n",
      "\n",
      "\n",
      "          [[[ 8,  9],\n",
      "            [12, 13]],\n",
      "\n",
      "           [[10, 11],\n",
      "            [14, 15]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        [[[[[16, 17],\n",
      "            [20, 21]],\n",
      "\n",
      "           [[18, 19],\n",
      "            [22, 23]]],\n",
      "\n",
      "\n",
      "          [[[24, 25],\n",
      "            [28, 29]],\n",
      "\n",
      "           [[26, 27],\n",
      "            [30, 31]]]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 32).view(2, 1, 4, 4) \n",
    "print(x)\n",
    "patches = x.unfold(2, 2, 2).unfold(3, 2, 2)\n",
    "print(patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c3a2869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/q2s37ndx6tg3lpzp3vp8xk_r0000gn/T/ipykernel_27909/4074788471.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(input_frame, dtype=torch.float32),\n",
      "/var/folders/y8/q2s37ndx6tg3lpzp3vp8xk_r0000gn/T/ipykernel_27909/4074788471.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(output_frame, dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 1, 4, 4]), torch.Size([10, 1, 4, 4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MakeVideoDataset(Dataset):\n",
    "\n",
    "    def __init__(self, video, input_length = 10, output_length = 10):\n",
    "        super().__init__()\n",
    "        self.video = video\n",
    "        self.input_length = input_length\n",
    "        self.output_length = output_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.video.shape[0] - self.input_length - self.output_length + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_frame = self.video[idx:idx+self.input_length]\n",
    "        output_frame = self.video[idx+self.input_length: idx+self.input_length+self.output_length]\n",
    "        return  (\n",
    "            torch.tensor(input_frame, dtype=torch.float32),\n",
    "            torch.tensor(output_frame, dtype=torch.float32)\n",
    "        )\n",
    "    \n",
    "    \n",
    "test = torch.randn(20, 1, 4, 4)\n",
    "out = MakeVideoDataset(test)\n",
    "x, y = out.__getitem__(0)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e0bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea04377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9451433b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992cd60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dce4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e3c3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072bed24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
